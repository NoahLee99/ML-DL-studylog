{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOFuJwIgC5SpB4e58+j6D8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahLee99/ML-DL-studylog/blob/main/Chapter%2008-1%20-%20%ED%95%A9%EC%84%B1%EA%B3%B1%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98%20%EA%B5%AC%EC%84%B1%20%EC%9A%94%EC%86%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **키워드**"
      ],
      "metadata": {
        "id": "dowl77k_y-YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- 합성곱: 밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형 계산이다.\n",
        "          하지만 밀집층과 달리 각 합성곱은 입력 전체가 아니라 일부만 사용하여 선형 계산을 수행한다.\n",
        "\n",
        "- 필터: 밀집층의 뉴런에 해당한다.\n",
        "        필터의 가중치와 절편을 종종 커널이라고 부른다.\n",
        "        자주 사용되는 커널의 크기는 (3, 3) 또는 (5, 5)이다.\n",
        "        커널의 깊이는 입력의 깊이와 같다.\n",
        "\n",
        "- 특성 맵: 합성곱 층이나 풀링 층의 출력 배열을 의미한다.\n",
        "           필터 하나가 특성 맵을 만든다.\n",
        "           합성곱 층에서 5개의 필터를 적용하면 5개의 특성 맵이 만들어진다.\n",
        "\n",
        "- 패딩: 합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀이다.\n",
        "        패딩을 사용하지 않는 것을 밸리드 패딩이라고 한다.\n",
        "        합성곱 층의 출력 크기를 입력과 동일하게 만들기 위해 입력에 패딩을 추가하는 것을 세임 패딩이라 한다.\n",
        "\n",
        "- 스트라이드: 합성곱 층에서 필터가 입력 위를 이동하는 크기이다.\n",
        "              일반적으로 스트라이드는 1픽셀을 사용한다.\n",
        "\n",
        "- 풀링: 가중치가 없고 특성 맵의 가로 세로 크기를 줄이는 역할을 수행한다.\n",
        "        대표적으로 최대 풀링과 평균 풀링이 있으며 (2, 2) 풀링으로 입력을 절반으로 줄인다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "sLATQod4zFvQ",
        "outputId": "f885dedb-e636-4cf2-891c-a95f103ccb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n- 합성곱: 밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형 계산이다.\\n          하지만 밀집층과 달리 각 합성곱은 입력 전체가 아니라 일부만 사용하여 선형 계산을 수행한다.\\n\\n- 필터: 밀집층의 뉴런에 해당한다. \\n        필터의 가중치와 절편을 종종 커널이라고 부른다.\\n        자주 사용되는 커널의 크기는 (3, 3) 또는 (5, 5)이다.\\n        커널의 깊이는 입력의 깊이와 같다.\\n\\n- 특성 맵: 합성곱 층이나 풀링 층의 출력 배열을 의미한다.\\n           필터 하나가 특성 맵을 만든다.\\n           합성곱 층에서 5개의 필터를 적용하면 5개의 특성 맵이 만들어진다.\\n\\n- 패딩: 합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀이다.\\n        패딩을 사용하지 않는 것을 밸리드 패딩이라고 한다.\\n        합성곱 층의 출력 크기를 입력과 동일하게 만들기 위해 입력에 패딩을 추가하는 것을 세임 패딩이라 한다.\\n\\n- 스트라이드: 합성곱 층에서 필터가 입력 위를 이동하는 크기이다.\\n              일반적으로 스트라이드는 1픽셀을 사용한다.\\n\\n- 풀링: 가중치가 없고 특성 맵의 가로 세로 크기를 줄이는 역할을 수행한다.\\n        대표적으로 최대 풀링과 평균 풀링이 있으며 (2, 2) 풀링으로 입력을 절반으로 줄인다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **합성곱 신경망의 구성 요소**"
      ],
      "metadata": {
        "id": "4DIM9Z68Ptah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "W1YgkcAFPm9Y",
        "outputId": "0e3df412-efd3-4ecb-980d-82ef49f8da6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n로지스틱 회귀의 성능은 81% 정도였는데 딥러닝의 성능은 87%로 크게 높아졌다.\\n그렇다면 도장을 찍듯이 패션 이미지의 특징을 잡아낼 수 있는 딥러닝 모델은 없을까?\\n\\n\"합성곱(convolution)\"은 마치 입력 데이터에 마법의 도장을 찍어 유용한 특성만 드러나게 하는 것으로 비유할 수 있다.\\n그럼 합성곱의 동작 원리를 자세히 살펴보자.\\n\\n7장에서 사용한 밀집층에는 뉴런마다 입력 개수만큼의 가중치가 있다.\\n즉 모든 입력에 가중치를 곱한다. (각 특성에 가중치(w)를 곱하고 절편값 더하기 --> 1개의 출력)\\n\\n인공 신경망은 처음에 가중치 w1~w10과 절편 b를 랜덤하게 초기화한 다음 에포크를 반복하면서\\n경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다.\\n이것이 바로 모델 훈련이다.\\n\\n예를 들어 밀집층에 뉴런이 3개 있다면 출력의 3개가 됩니다.\\n입력 개수에 상관없이 동일하다.\\n7장의 예시를 다시 떠올려 보면 패션 MNIST 이미지에 있는 784개의 픽셀을 입력받는 은닉층의 뉴런 개수가 100개면\\n뉴런마다 하나씩 출력도 100개가 된다.\\n\\n합성곱은 밀집층의 계산과 조금 다르다.\\n입력 데이터 전체에 가중치를 적용하는 것이 아니라, 일부에 가중치를 곱한다! \\n(처음 가중치 개수를 정함 --> 각 특성(가중치 개수만큼)에 가중치(w)를 곱하고 절편값 더하기 --> 1개의 출력 --> 마지막 특성까지 가중치 개수만큼 순차적으로 내려가며 계산)\\nex) 10개의 특성, 3개의 가중치(w) --> 총 8개의 출력 (= 10-2)\\n\\n가중치 w1~w3이 입력의 처음 3개 특성과 곱해져 1개의 출력을 만든다. \\n그다음이 중요한데, 이 뉴런이 한 칸 아래로 이동해 두 번째부터 네 번째 특성과 곱해져 새로운 출력을 만든다.\\n여기에서 중요한 것은 첫 번째 합성곱에 사용된 가중치 w1~w3과 절편 b가 두 번째 합성곱에도 동일하게 사용된다!\\n이렇게 한 칸씩 아래로 이동하면서 출력을 만드는 것이 합성곱이다.\\n여기에서는 이 뉴런의 가중치가 3개이기 때문에 모두 8개의 출력이 만들어진다.\\n\\n밀집층의 뉴런을 입력 개수만큼 10개의 가중치를 가지고 1개의 출력을 만든다.\\n합성곱 층의 뉴런은 3개의 가중치를 가지고 8개의 출력을 만든다.\\n눈치챘을지 모르지만 합성곱 층의 뉴런에 있는 가중치 개수는 정하기 나름이다! 즉 또 다른 하이퍼파라미터이다.\\n이는 마치 입력 데이터 위를 이동하면서 같은 도장으로 하나씩 찍는 것처럼 생각할 수 있다.\\n도장을 찍을 때마다 출력이 하나씩 만들어지는 것이다.\\n\\n이전에 그렸던 신경망 층의 그림은 뉴런이 길게 늘어서 있고 서로 조밀하게 연결되어 있었다.\\n그런데 합성곱에서는 뉴런이 입력 위를 이동하면서 출력을 만들기 때문에 이런 식으로 표한하기가 어렵다.\\n또 뉴런이라고 부르기도 어색하다.\\n\"합성공 신경망(convolutional neural network, CNN)\"에서는 완전 연결 신경망과 달리 뉴런을 \"필터(filter)\"라고 부른다. \\n혹은 \"커널(kernel)\"이라고 부른다.\\n\\n*완전 연결 신경망이란 7장에서 만들었던 신경망으로, 완전 연결 층(밀집층)만 사용하여 만든 신경망을 일컫는다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "'''\n",
        "로지스틱 회귀의 성능은 81% 정도였는데 딥러닝의 성능은 87%로 크게 높아졌다.\n",
        "그렇다면 도장을 찍듯이 패션 이미지의 특징을 잡아낼 수 있는 딥러닝 모델은 없을까?\n",
        "\n",
        "\"합성곱(convolution)\"은 마치 입력 데이터에 마법의 도장을 찍어 유용한 특성만 드러나게 하는 것으로 비유할 수 있다.\n",
        "그럼 합성곱의 동작 원리를 자세히 살펴보자.\n",
        "\n",
        "7장에서 사용한 밀집층에는 뉴런마다 입력 개수만큼의 가중치가 있다.\n",
        "즉 모든 입력에 가중치를 곱한다. (각 특성에 가중치(w)를 곱하고 절편값 더하기 --> 1개의 출력)\n",
        "\n",
        "인공 신경망은 처음에 가중치 w1~w10과 절편 b를 랜덤하게 초기화한 다음 에포크를 반복하면서\n",
        "경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다.\n",
        "이것이 바로 모델 훈련이다.\n",
        "\n",
        "예를 들어 밀집층에 뉴런이 3개 있다면 출력의 3개가 됩니다.\n",
        "입력 개수에 상관없이 동일하다.\n",
        "7장의 예시를 다시 떠올려 보면 패션 MNIST 이미지에 있는 784개의 픽셀을 입력받는 은닉층의 뉴런 개수가 100개면\n",
        "뉴런마다 하나씩 출력도 100개가 된다.\n",
        "\n",
        "합성곱은 밀집층의 계산과 조금 다르다.\n",
        "입력 데이터 전체에 가중치를 적용하는 것이 아니라, 일부에 가중치를 곱한다!\n",
        "(처음 가중치 개수를 정함 --> 각 특성(가중치 개수만큼)에 가중치(w)를 곱하고 절편값 더하기 --> 1개의 출력 --> 마지막 특성까지 가중치 개수만큼 순차적으로 내려가며 계산)\n",
        "ex) 10개의 특성, 3개의 가중치(w) --> 총 8개의 출력 (= 10-2)\n",
        "\n",
        "가중치 w1~w3이 입력의 처음 3개 특성과 곱해져 1개의 출력을 만든다.\n",
        "그다음이 중요한데, 이 뉴런이 한 칸 아래로 이동해 두 번째부터 네 번째 특성과 곱해져 새로운 출력을 만든다.\n",
        "여기에서 중요한 것은 첫 번째 합성곱에 사용된 가중치 w1~w3과 절편 b가 두 번째 합성곱에도 동일하게 사용된다!\n",
        "이렇게 한 칸씩 아래로 이동하면서 출력을 만드는 것이 합성곱이다.\n",
        "여기에서는 이 뉴런의 가중치가 3개이기 때문에 모두 8개의 출력이 만들어진다.\n",
        "\n",
        "밀집층의 뉴런을 입력 개수만큼 10개의 가중치를 가지고 1개의 출력을 만든다.\n",
        "합성곱 층의 뉴런은 3개의 가중치를 가지고 8개의 출력을 만든다.\n",
        "눈치챘을지 모르지만 합성곱 층의 뉴런에 있는 가중치 개수는 정하기 나름이다! 즉 또 다른 하이퍼파라미터이다.\n",
        "이는 마치 입력 데이터 위를 이동하면서 같은 도장으로 하나씩 찍는 것처럼 생각할 수 있다.\n",
        "도장을 찍을 때마다 출력이 하나씩 만들어지는 것이다.\n",
        "\n",
        "이전에 그렸던 신경망 층의 그림은 뉴런이 길게 늘어서 있고 서로 조밀하게 연결되어 있었다.\n",
        "그런데 합성곱에서는 뉴런이 입력 위를 이동하면서 출력을 만들기 때문에 이런 식으로 표한하기가 어렵다.\n",
        "또 뉴런이라고 부르기도 어색하다.\n",
        "\"합성공 신경망(convolutional neural network, CNN)\"에서는 완전 연결 신경망과 달리 뉴런을 \"필터(filter)\"라고 부른다.\n",
        "혹은 \"커널(kernel)\"이라고 부른다.\n",
        "\n",
        "*완전 연결 신경망이란 7장에서 만들었던 신경망으로, 완전 연결 층(밀집층)만 사용하여 만든 신경망을 일컫는다.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "케라스 API와 이름을 맞추기 위해 뉴런 개수를 이야기할 때는 필터라 부르고,\n",
        "입력에 곱해지는 가중치를 의미할 때는 커널이라고 부르겠다.\n",
        "합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것이다.\n",
        "\n",
        "입력이 2차원 배열이면 필터(도장)도 2차원이어야 한다.\n",
        "여기 4x4 크기의 2차원 배열 데이터가 있다.\n",
        "필터의 커널 크기를 (3, 3)으로 가정해보자. (이 커널 크기는 우리가 지정해야 할 하이퍼파라미터임)\n",
        "그다음 왼쪽 위 모서리에서부터 합성곱을 시작한다.\n",
        "입력의 9개 원소와 커널의 9개 가중치를 곱한 후 (물론 여기에서도 절편을 더한다) 1개의 출력을 만든다.\n",
        "\n",
        "그다음에는 필터가 오른쪽을 한 칸 이동하여 합성곱을 또 수행한다.\n",
        "입력의 너비가 4이므로 더 이상 오른쪽으로 한 칸 이동할 수 없다.\n",
        "이럴 때는 아래로 한 칸 이동한 다음 다시 왼쪽에서부터 합성곱을 수행한다.\n",
        "그리고 다시 오른쪽으로 한 칸 이동한다.\n",
        "\n",
        "합성곱은 마치 도장을 찍듯이 왼쪽 위에서 오른쪽 맨 아래까지 이동하면서 출력을 만든다.\n",
        "계산식을 밀집층과 크게 다르지 않다.\n",
        "입력과 가중치의 행과 열을 맞추어 곱셈하고 모두 더하는 게 전부이다.\n",
        "아까의 예시에서 필터(도장)는 모두 4번 이동할 수 있기 때문에 4개의 출력을 만든다.\n",
        "이때 4개의 출력을 필터가 입력에 놓은 위치에 맞게 2차원으로 배치한다.\n",
        "즉 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래 모두 4개의 위치에 해당 값을 놓는다.\n",
        "이렇게 출력을 2차원으로 표현하면 (4, 4)(4x4) 크기의 입력을 (2, 2)(2x2) 크기로 압축한 느낌이 나지 않는가?\n",
        "합성곱 계산을 통해 얻은 출력을 특별히 \"특 맵(feature map)\"이라 부른다.\n",
        "\n",
        "밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서도 여러 개의 필터를 사용한다.\n",
        "하나만 사용할 이유는 없다.\n",
        "여러 개의 필터를 사용하면 만들어진 특성 맵은 순서대로 차곡차곡 쌓인다.\n",
        "(2, 2) 크기의 특성 맵을 쌓으면 3차원 배열이 된다.\n",
        "만약 3개의 필터를 사용했다면 (2, 2, 3) 크기의 3차원 배열이 된다. ((x, y, z)에서 z는 필터의 개수를 의미함)\n",
        "\n",
        "여기서 3개의 필터의 가중치(커널)들은 각각 다른 값이다.\n",
        "밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층에 있는 피렅의 가중치(커널)도 모두 다르다.\n",
        "너무 당연하지만 같은 가중치를 가진 필터를 여러 개 사용할 이유가 없기 때문이다.\n",
        "\n",
        "합성곱의 실제 계산은 밀집층과 동일하게 단순히 입력과 가중치를 곱하는 것이지만 2차원 형태를 유지하는 점이 다르다.\n",
        "또 입력보다 훨씬 작은 크기의 커널을 사용하고 입력 배열을 이동하며 2차원 특성 맵을 만든다.\n",
        "이렇게 2차원 구조를 그대로 사용하기 때문에 합성곱 신경망이 이미지 처리 분야에서 뛰어난 성능을 발휘한다.\n",
        "그럼 케라스에서 합성곱 층을 어떻게 만드는지 알아보자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "NY4OUSioU07D",
        "outputId": "7593af0c-a1fa-4a2f-af57-b79027e1ba1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n케라스 API와 이름을 맞추기 위해 뉴런 개수를 이야기할 때는 필터라 부르고, \\n입력에 곱해지는 가중치를 의미할 때는 커널이라고 부르겠다.\\n합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것이다.\\n\\n입력이 2차원 배열이면 필터(도장)도 2차원이어야 한다.\\n여기 4x4 크기의 2차원 배열 데이터가 있다.\\n필터의 커널 크기를 (3, 3)으로 가정해보자. (이 커널 크기는 우리가 지정해야 할 하이퍼파라미터임)\\n그다음 왼쪽 위 모서리에서부터 합성곱을 시작한다.\\n입력의 9개 원소와 커널의 9개 가중치를 곱한 후 (물론 여기에서도 절편을 더한다) 1개의 출력을 만든다.\\n\\n그다음에는 필터가 오른쪽을 한 칸 이동하여 합성곱을 또 수행한다.\\n입력의 너비가 4이므로 더 이상 오른쪽으로 한 칸 이동할 수 없다.\\n이럴 때는 아래로 한 칸 이동한 다음 다시 왼쪽에서부터 합성곱을 수행한다.\\n그리고 다시 오른쪽으로 한 칸 이동한다.\\n\\n합성곱은 마치 도장을 찍듯이 왼쪽 위에서 오른쪽 맨 아래까지 이동하면서 출력을 만든다.\\n계산식을 밀집층과 크게 다르지 않다.\\n입력과 가중치의 행과 열을 맞추어 곱셈하고 모두 더하는 게 전부이다.\\n아까의 예시에서 필터(도장)는 모두 4번 이동할 수 있기 때문에 4개의 출력을 만든다.\\n이때 4개의 출력을 필터가 입력에 놓은 위치에 맞게 2차원으로 배치한다.\\n즉 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래 모두 4개의 위치에 해당 값을 놓는다.\\n이렇게 출력을 2차원으로 표현하면 (4, 4)(4x4) 크기의 입력을 (2, 2)(2x2) 크기로 압축한 느낌이 나지 않는가?\\n합성곱 계산을 통해 얻은 출력을 특별히 \"특 맵(feature map)\"이라 부른다.\\n\\n밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서도 여러 개의 필터를 사용한다.\\n하나만 사용할 이유는 없다.\\n여러 개의 필터를 사용하면 만들어진 특성 맵은 순서대로 차곡차곡 쌓인다.\\n(2, 2) 크기의 특성 맵을 쌓으면 3차원 배열이 된다.\\n만약 3개의 필터를 사용했다면 (2, 2, 3) 크기의 3차원 배열이 된다. ((x, y, z)에서 z는 필터의 개수를 의미함)\\n\\n여기서 3개의 필터의 가중치(커널)들은 각각 다른 값이다.\\n밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층에 있는 피렅의 가중치(커널)도 모두 다르다.\\n너무 당연하지만 같은 가중치를 가진 필터를 여러 개 사용할 이유가 없기 때문이다.\\n\\n합성곱의 실제 계산은 밀집층과 동일하게 단순히 입력과 가중치를 곱하는 것이지만 2차원 형태를 유지하는 점이 다르다.\\n또 입력보다 훨씬 작은 크기의 커널을 사용하고 입력 배열을 이동하며 2차원 특성 맵을 만든다.\\n이렇게 2차원 구조를 그대로 사용하기 때문에 합성곱 신경망이 이미지 처리 분야에서 뛰어난 성능을 발휘한다.\\n그럼 케라스에서 합성곱 층을 어떻게 만드는지 알아보자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **케라스 합성곱 층**\n",
        "\n"
      ],
      "metadata": {
        "id": "UOMrgrskaNJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "케라스의 층은 모두 keras.layers 패키지 아래 클래스로 구현되어 있다.\n",
        "합성곱 층도 마찬가지이다.\n",
        "특별히 입력 배열을 이동하는(왼쪽에서 오른쪽으로, 위에서 아래로) 이동하는 합성곱은 Conv2D 클래스로 제공한다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Qr_BjwHXaMSR",
        "outputId": "2659480c-fad7-4245-86ae-3176f61d646a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n케라스의 층은 모두 keras.layers 패키지 아래 클래스로 구현되어 있다.\\n합성곱 층도 마찬가지이다.\\n특별히 입력 배열을 이동하는(왼쪽에서 오른쪽으로, 위에서 아래로) 이동하는 합성곱은 Conv2D 클래스로 제공한다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "keras.layers.Conv2D(10, kernel_size=(3, 3), activation='relu') # 10은 필터의 개수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGQxwPi7ajLe",
        "outputId": "f51f8b89-e2b2-42b1-a84b-5d5114033b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Conv2D name=conv2d_3, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Conv2D 클래스의 첫 번째 매개변수는 필터(도장)의 개수이다.\n",
        "kernel_size 매개변수는 필터에 사용할 커널의 크기를 지정한다.\n",
        "필터의 개수와 커널의 크기는 반드시 지정해야 하는 매개변수이다!\n",
        "마지막으로 밀집층에서처럼 활성화 함수를 지정한다.\n",
        "여기에서는 렐루 함수를 선택했다.\n",
        "\n",
        "* 그럼 특성 맵은 활성화 함수를 적용하기 전인가? 후인가?\n",
        "  - 결론부터 이야기하자면 후이다.\n",
        "    완전 연결 신경망에서처럼 합성곱 신경망에서도 종종 활성화 함수를 언급하지 않는다.\n",
        "    일반적으로 특성 맵은 활성화 함수를 통과한 값을 나타낸다.\n",
        "    합성곱에서는 활성화 출력이란 표현을 잘 쓰지 않는다. 혼동하지 말자.\n",
        "\n",
        "* 커널의 크기는 어떻게 정할까?\n",
        "  - 앞에서 잠깐 언급했지만 커널의 크기는 하이퍼파라미터이다.\n",
        "    따라서 여러 가지 값을 시도해 봐야 한다.\n",
        "    하지만 보통 (3, 3)이나 (5, 5) 크기가 권장된다.\n",
        "\n",
        "케라스 API를 사용하면 합성곱 층을 사용하는 것이 어렵지 않다.\n",
        "이전에 Dense 층을 사용했떤 자리에 대신 Conv2D 층을 넣으면 된다.\n",
        "다만 Kernel_size와 같이 추가적인 매개변수들을 고려해야 한다.\n",
        "\n",
        "그렇다면 합성곱 신경망의 정의는 무엇일까?\n",
        "일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 합성곱 신경망이라 부른다.\n",
        "즉 꼭 합성곱 층만 사용한 신경망을 합성곱 신경망이라고 부르는 것은 아니다.\n",
        "이전 장에서 보았듯이 클래스에 대한 확률을 계산하려면\n",
        "마지막 층에 클래스 개수만큼의 뉴런을 가진 밀집층을 두는 것이 일반적이기 때문이다.\n",
        "\n",
        "합성곱 층이 구현된 케라스 API를 잠시 살펴보았다.\n",
        "그런데 합성곱 신경망을 실제 만들려면 조금 더 알아야 할 것이 있다.\n",
        "그것은 바로 패딩과 스트라이드이다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "06GNs2U1a2dF",
        "outputId": "e05a3b4b-6a87-483b-d3aa-94c0838cbeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nConv2D 클래스의 첫 번째 매개변수는 필터(도장)의 개수이다.\\nkernel_size 매개변수는 필터에 사용할 커널의 크기를 지정한다.\\n필터의 개수와 커널의 크기는 반드시 지정해야 하는 매개변수이다!\\n마지막으로 밀집층에서처럼 활성화 함수를 지정한다.\\n여기에서는 렐루 함수를 선택했다.\\n\\n* 그럼 특성 맵은 활성화 함수를 적용하기 전인가? 후인가?\\n  - 결론부터 이야기하자면 후이다. \\n    완전 연결 신경망에서처럼 합성곱 신경망에서도 종종 활성화 함수를 언급하지 않는다.\\n    일반적으로 특성 맵은 활성화 함수를 통과한 값을 나타낸다.\\n    합성곱에서는 활성화 출력이란 표현을 잘 쓰지 않는다. 혼동하지 말자.\\n\\n* 커널의 크기는 어떻게 정할까?\\n  - 앞에서 잠깐 언급했지만 커널의 크기는 하이퍼파라미터이다.\\n    따라서 여러 가지 값을 시도해 봐야 한다.\\n    하지만 보통 (3, 3)이나 (5, 5) 크기가 권장된다.\\n\\n케라스 API를 사용하면 합성곱 층을 사용하는 것이 어렵지 않다.\\n이전에 Dense 층을 사용했떤 자리에 대신 Conv2D 층을 넣으면 된다.\\n다만 Kernel_size와 같이 추가적인 매개변수들을 고려해야 한다.\\n\\n그렇다면 합성곱 신경망의 정의는 무엇일까?\\n일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 합성곱 신경망이라 부른다.\\n즉 꼭 합성곱 층만 사용한 신경망을 합성곱 신경망이라고 부르는 것은 아니다.\\n이전 장에서 보았듯이 클래스에 대한 확률을 계산하려면 \\n마지막 층에 클래스 개수만큼의 뉴런을 가진 밀집층을 두는 것이 일반적이기 때문이다.\\n\\n합성곱 층이 구현된 케라스 API를 잠시 살펴보았다.\\n그런데 합성곱 신경망을 실제 만들려면 조금 더 알아야 할 것이 있다.\\n그것은 바로 패딩과 스트라이드이다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **패딩과 스트라이드**"
      ],
      "metadata": {
        "id": "CThV23m0cb6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "앞에서 예로 들었던 합성곱 계산은 (4, 4) 크기의 입력에 (3, 3) 크기의 커널을 적용하여 (2, 2) 크기의 특성 맵을 만들었다.\n",
        "그런데 만약 커널 크기는 (3, 3)으로 그대로 두고 출력의 크기를 입력과 동일하게 (4, 4)로 만들려면 어떻게 해야 할까?\n",
        "\n",
        "(4, 4) 입력과 동일한 크기의 출력을 만들려면 마치 더 큰 입력에 합성곱을 하는 척해야 한다.\n",
        "예를 들어 실제 입력 크기는 (4, 4)이지만 (6, 6)처럼 다룬다고 가정해 보자.\n",
        "입력이 (6, 6) 크기이면 (3, 3) 크기의 커널로 합성곱을 했을 때 출력의 크기가 얼마나 될까?\n",
        "\n",
        "(3, 3) 커널로 도장을 찍어 보면 출력의 크기가 (4, 4)가 되는 것을 알 수 있다.\n",
        "왼쪽 위에서 오른쪽 아래까지 한 칸씩 이동하면서 합성곱을 수행하면 입력과 같은 (4, 4)크기의 출력을 만들 수 있다.\n",
        "\n",
        "이렇게 입력 배열의 주위를 가상의 원소로 채우는 것을 \"패딩(padding)\"이라고 한다.\n",
        "html의 content와의 간격을 의미하는 padding 매개변수를 생각하면 이해가 쉬울 것이다.\n",
        "CNN으로 돌아오자면, 실제 입력값이 아니기 때문에 패딩은 0으로 채운다.\n",
        "즉 (4, 4) 크기의 입력에 0을 1개 패딩하면, 0의 값으로 한 칸씩 둘러쌓인 (6, 6) 크기의 입력이 된다.\n",
        "패딩의 역할은 순전히 커널이 도장을 찍을 횟수를 늘려주는 것밖에는 없다.\n",
        "실제 값은 0으로 채워져 있기 때문에 계산에 영향을 미치지는 않는다.\n",
        "쉽게 말해 패딩은 합성곱 연산에 기여도를 올리기 위해 사용하는 것이다.\n",
        "\n",
        "이렇게 입력과 특성 맵의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것을 \"세임 패딩(same padding)\"이라 부른다.\n",
        "합성곱 신경망에서는 세임 패딩이 많이 사용된다.\n",
        "바꿔 말하면 입력과 특성 맵의 크기를 동일하게 만드는 경우가 아주 많다.\n",
        "\n",
        "패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우를 \"밸리드 패딩(valid padding)\"이라고 한다.\n",
        "밸리드 패딩은 특성 맵의 크기가 줄어들 수밖에 없다.\n",
        "\n",
        "그럼 왜 합성곱에서는 패딩을 즐겨 사용할까?\n",
        "만약 패딩이 없다면 (4, 4) 크기의 입력에 패딩 없이 합성곱을 한다면\n",
        "네 모서리에 있는 4개의 값들은 커널 도장에 딱 한 번만 찍히기 때문이다.\n",
        "\n",
        "반면 다른 원소들은 2번 이상 커널과 계산된다.\n",
        "가운데 4개 원소들은 4번의 합성곱 계산에 모두 포함된다.\n",
        "만약 이 입력을 이미지라고 생각하면 모서리에 있는 중요한 정보가 특성 맵으로 잘 전달되지 않을 가능성이 높다.\n",
        "반면 가운데 있는 정보는 두드러지게 표현된다.\n",
        "\n",
        "패딩을 하지 않을 경우 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율은 크게 차이나게 된다.(4:1)\n",
        "1픽셀을 패딩하면 이 차이는 크게 줄어든다.(9:4)\n",
        "만약 2픽셀을 패딩하면 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율이 동일해진다.(1:1)\n",
        "\n",
        "적절한 패딩은 이처럼 이미지 주변에 있는 정보를 잃어버리지 않도록 도와준다.\n",
        "앞에서도 언급했지만 일반적인 합성곱 신경망에서는 세임 패딩이 많이 사용된다.\n",
        "케라스 Conv2D 클래스에서는 padding 매개변수로 패딩을 지정할 수 있다.\n",
        "기본값은 'valid'로 밸리드 패딩을 나타낸다.\n",
        "세임 패디을 사용하려면 'same'으로 지정한다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "9odaxuPlcd1a",
        "outputId": "05abbb53-3355-4c03-ea06-9dfc2bee39f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n앞에서 예로 들었던 합성곱 계산은 (4, 4) 크기의 입력에 (3, 3) 크기의 커널을 적용하여 (2, 2) 크기의 특성 맵을 만들었다.\\n그런데 만약 커널 크기는 (3, 3)으로 그대로 두고 출력의 크기를 입력과 동일하게 (4, 4)로 만들려면 어떻게 해야 할까?\\n\\n(4, 4) 입력과 동일한 크기의 출력을 만들려면 마치 더 큰 입력에 합성곱을 하는 척해야 한다.\\n예를 들어 실제 입력 크기는 (4, 4)이지만 (6, 6)처럼 다룬다고 가정해 보자.\\n입력이 (6, 6) 크기이면 (3, 3) 크기의 커널로 합성곱을 했을 때 출력의 크기가 얼마나 될까?\\n\\n(3, 3) 커널로 도장을 찍어 보면 출력의 크기가 (4, 4)가 되는 것을 알 수 있다.\\n왼쪽 위에서 오른쪽 아래까지 한 칸씩 이동하면서 합성곱을 수행하면 입력과 같은 (4, 4)크기의 출력을 만들 수 있다.\\n\\n이렇게 입력 배열의 주위를 가상의 원소로 채우는 것을 \"패딩(padding)\"이라고 한다.\\nhtml의 content와의 간격을 의미하는 padding 매개변수를 생각하면 이해가 쉬울 것이다.\\nCNN으로 돌아오자면, 실제 입력값이 아니기 때문에 패딩은 0으로 채운다.\\n즉 (4, 4) 크기의 입력에 0을 1개 패딩하면, 0의 값으로 한 칸씩 둘러쌓인 (6, 6) 크기의 입력이 된다.\\n패딩의 역할은 순전히 커널이 도장을 찍을 횟수를 늘려주는 것밖에는 없다.\\n실제 값은 0으로 채워져 있기 때문에 계산에 영향을 미치지는 않는다.\\n쉽게 말해 패딩은 합성곱 연산에 기여도를 올리기 위해 사용하는 것이다.\\n\\n이렇게 입력과 특성 맵의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것을 \"세임 패딩(same padding)\"이라 부른다.\\n합성곱 신경망에서는 세임 패딩이 많이 사용된다.\\n바꿔 말하면 입력과 특성 맵의 크기를 동일하게 만드는 경우가 아주 많다.\\n\\n패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우를 \"밸리드 패딩(valid padding)\"이라고 한다.\\n밸리드 패딩은 특성 맵의 크기가 줄어들 수밖에 없다.\\n\\n그럼 왜 합성곱에서는 패딩을 즐겨 사용할까?\\n만약 패딩이 없다면 (4, 4) 크기의 입력에 패딩 없이 합성곱을 한다면 \\n네 모서리에 있는 4개의 값들은 커널 도장에 딱 한 번만 찍히기 때문이다.\\n\\n반면 다른 원소들은 2번 이상 커널과 계산된다.\\n가운데 4개 원소들은 4번의 합성곱 계산에 모두 포함된다.\\n만약 이 입력을 이미지라고 생각하면 모서리에 있는 중요한 정보가 특성 맵으로 잘 전달되지 않을 가능성이 높다.\\n반면 가운데 있는 정보는 두드러지게 표현된다.\\n\\n패딩을 하지 않을 경우 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율은 크게 차이나게 된다.(4:1)\\n1픽셀을 패딩하면 이 차이는 크게 줄어든다.(9:4)\\n만약 2픽셀을 패딩하면 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율이 동일해진다.(1:1)\\n\\n적절한 패딩은 이처럼 이미지 주변에 있는 정보를 잃어버리지 않도록 도와준다.\\n앞에서도 언급했지만 일반적인 합성곱 신경망에서는 세임 패딩이 많이 사용된다.\\n케라스 Conv2D 클래스에서는 padding 매개변수로 패딩을 지정할 수 있다.\\n기본값은 \\'valid\\'로 밸리드 패딩을 나타낸다.\\n세임 패디을 사용하려면 \\'same\\'으로 지정한다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Conv2D(10, kernel_size=(3, 3), activation='relu', padding='same')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbH6dvWbhKlz",
        "outputId": "0027ef7f-8142-43a7-fa69-986df9c29771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Conv2D name=conv2d_4, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "지금까지 본 합성곱 연산은 좌우, 위아래로 한 칸씩 이동했다.\n",
        "하지만 두 칸씩 건너뛸 수도 있다.\n",
        "이렇게 두 칸씩 이동하면 만들어지는 특성 맵의 크기는 더 작아질 것이다.\n",
        "커널 도장을 찍는 횟수가 줄어드니까 말이다.\n",
        "\n",
        "이러한 이동의 크기를 \"스트라이드(strdie)\"라고 한다. (=보폭)\n",
        "기본적으로 스트라이드는 1이다.\n",
        "즉 한 칸씩 이동한다.\n",
        "이 값이 케라스 Conv2D의 strides 매개변수의 기본값이다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-YnqkQ7PhRr3",
        "outputId": "e5232ef2-5b5e-4861-ec5e-a9706d89bbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n지금까지 본 합성곱 연산은 좌우, 위아래로 한 칸씩 이동했다.\\n하지만 두 칸씩 건너뛸 수도 있다.\\n이렇게 두 칸씩 이동하면 만들어지는 특성 맵의 크기는 더 작아질 것이다.\\n커널 도장을 찍는 횟수가 줄어드니까 말이다.\\n\\n이러한 이동의 크기를 \"스트라이드(strdie)\"라고 한다. (=보폭)\\n기본적으로 스트라이드는 1이다.\\n즉 한 칸씩 이동한다.\\n이 값이 케라스 Conv2D의 strides 매개변수의 기본값이다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Conv2D(10, kernel_size=(3, 3), activation='relu',\n",
        "                    padding='same', strides=1) # 1픽셀씩 이동한다는 뜻"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K5-hyP3hpM_",
        "outputId": "ef5c4a21-4292-4c46-837c-b06e4a1357b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Conv2D name=conv2d_5, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "strides 매개변수는 오른쪽으로 이동하는 크기와 아래쪽으로 이동하는 크기를 (1, 1)과 같이 튜플을 사용해 각각 지정 가능하다.\n",
        "하지만 커널의 이동 크기를 가로 세로 방향으로 다르게 지정하는 경우는 거의 없다.\n",
        "또 1보다 큰 스트라이드를 사용하는 경우도 드물다.\n",
        "대부분 기본값을 그대로 사용하기 때문에 strides 매개변수는 잘 사용하지 않는다.\n",
        "\n",
        "지금까지 패딩과 스트라이드에 대해 알아보았다.\n",
        "조금 복잡해 보이지만 케라스 API를 사용하면 Conv2D 클래스의 옵션으로 간단히 처리할 수 있다.\n",
        "꼭 기억해야 할 것은 세임 패딩의 경우 입력과 만들어진 특성 맵의 가로 세로 크기가 같다는 점이다!\n",
        "그럼 합성곱 신경망의 마지막 구성 요소인 풀링으로 넘어가 보자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "XfQ7FnaChxWk",
        "outputId": "bf2544b5-d30c-461a-b8a3-9e6d14e4142f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nstrides 매개변수는 오른쪽으로 이동하는 크기와 아래쪽으로 이동하는 크기를 (1, 1)과 같이 튜플을 사용해 각각 지정 가능하다.\\n하지만 커널의 이동 크기를 가로 세로 방향으로 다르게 지정하는 경우는 거의 없다.\\n또 1보다 큰 스트라이드를 사용하는 경우도 드물다.\\n대부분 기본값을 그대로 사용하기 때문에 strides 매개변수는 잘 사용하지 않는다.\\n\\n지금까지 패딩과 스트라이드에 대해 알아보았다.\\n조금 복잡해 보이지만 케라스 API를 사용하면 Conv2D 클래스의 옵션으로 간단히 처리할 수 있다.\\n꼭 기억해야 할 것은 세임 패딩의 경우 입력과 만들어진 특성 맵의 가로 세로 크기가 같다는 점이다!\\n그럼 합성곱 신경망의 마지막 구성 요소인 풀링으로 넘어가 보자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **풀링**"
      ],
      "metadata": {
        "id": "blcz74h0iPLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\"풀링(pooling)\"은 합성곱 층에서 만든 특성 맵의 가로 세로 크기를 줄이는 역할을 수행한다.\n",
        "하지만 특성 맵의 개수는 줄이지 않는다.\n",
        "예를 들면 (2, 2, 3) 크기의 특성 맵에 풀링을 적용하면,\n",
        "마지막 차원인 개수는 그대로 유지하고 너비와 높이만 줄어들어 (1, 1, 3) 크기의 특성 맵이 된다.\n",
        "풀링은 특성 맵에 커널 없는 필터를 적용하는 것과 비슷하게 생각하면 좋다.\n",
        "\n",
        "풀링도 합성곱처럼 입력 배열을 지나가면서 도장을 찍는다.\n",
        "아까의 예시에서는 (2, 2) 크기로 풀링을 한다.\n",
        "하지만 풀링에는 가중치가 없다!\n",
        "대신 도장을 찍은 영역에서 가장 큰 값을 고르거나 평균값을 계산한다.\n",
        "이를 각각 \"최대 풀링(max pooling)\"과 \"평균 풀링(average pooling)\"이라고 부른다.\n",
        "풀링은 합성곱 층과 뚜렷이 구분되기 때문에 풀링 층이라고 부르겠다.\n",
        "\n",
        "조금 더 자세히 설명해 보자.\n",
        "가령 (4, 4) 크기의 특성 맵이 있다고 가정해 보자.\n",
        "여기에 (2, 2) 최대 풀링을 적용하면 절반으로 크기가 줄어든다. (일반적으로 strdies가 명시되지 않으면 풀링 영역 크기와 같음 =2칸)\n",
        "(쉽게 말해 2칸의 strides로 특성 맵을 지나다니며 각 이동 마다 최대 값을 뽑아 한 데 모으는 것이다.)\n",
        "최대 풀링은 가장 큰 값을 고르기 때문에 첫 번째 (2, 2) 영역에서 최대값을 고르고\n",
        "그다음 차례로 각 영역의 최대값을 골라 (2, 2) 크기의 출력을 만든다.\n",
        "특성 맵이 여러 개라면 동일한 작업을 반복한다.\n",
        "즉 10개의 특성 맵이 있다면 풀링을 거친 특성 맵도 10개가 된다. (10번 반복 수행)\n",
        "\n",
        "* 풀링 층의 출력도 특성 맵이라고 하는가?\n",
        "  - 그렇다. 합성곱 신경망에서는 합성곱 층과 풀링 층에서 출력되는 값을 모두 특성 맵이라 부른다.\n",
        "\n",
        "눈여겨볼 점은 풀링 영역이 두 칸씩 이동했다는 점이다.\n",
        "합성곱에서는 커널이 한 칸씩 이동했기 때문에 겹치는 부분이 있었다.\n",
        "하지만 풀링에서는 겹치지 않고 이동한다.\n",
        "따라서 풀리의 크기가 (2, 2)이면 가로 세로 두 칸씩 이동한다.\n",
        "즉 스트라이드가 2이다.\n",
        "(3, 3) 풀링이면 가로 세로 세 칸씩 이동한다.\n",
        "\n",
        "풀링은 가중치가 없고 풀링 크기와 스트라이드가 같기 때문에 이해하기 쉽다.\n",
        "또 패딩이 없다.\n",
        "케라스에서는 MaxPooling2D 클래스로 풀링을 수행할 수 있다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "_BUKqy5yiQlL",
        "outputId": "172269b8-2e07-4394-c907-b115aef03139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\"풀링(pooling)\"은 합성곱 층에서 만든 특성 맵의 가로 세로 크기를 줄이는 역할을 수행한다.\\n하지만 특성 맵의 개수는 줄이지 않는다.\\n예를 들면 (2, 2, 3) 크기의 특성 맵에 풀링을 적용하면, \\n마지막 차원인 개수는 그대로 유지하고 너비와 높이만 줄어들어 (1, 1, 3) 크기의 특성 맵이 된다.\\n풀링은 특성 맵에 커널 없는 필터를 적용하는 것과 비슷하게 생각하면 좋다.\\n\\n풀링도 합성곱처럼 입력 배열을 지나가면서 도장을 찍는다.\\n아까의 예시에서는 (2, 2) 크기로 풀링을 한다.\\n하지만 풀링에는 가중치가 없다!\\n대신 도장을 찍은 영역에서 가장 큰 값을 고르거나 평균값을 계산한다.\\n이를 각각 \"최대 풀링(max pooling)\"과 \"평균 풀링(average pooling)\"이라고 부른다.\\n풀링은 합성곱 층과 뚜렷이 구분되기 때문에 풀링 층이라고 부르겠다.\\n\\n조금 더 자세히 설명해 보자.\\n가령 (4, 4) 크기의 특성 맵이 있다고 가정해 보자.\\n여기에 (2, 2) 최대 풀링을 적용하면 절반으로 크기가 줄어든다. (일반적으로 strdies가 명시되지 않으면 풀링 영역 크기와 같음 =2칸)\\n(쉽게 말해 2칸의 strides로 특성 맵을 지나다니며 각 이동 마다 최대 값을 뽑아 한 데 모으는 것이다.)\\n최대 풀링은 가장 큰 값을 고르기 때문에 첫 번째 (2, 2) 영역에서 최대값을 고르고\\n그다음 차례로 각 영역의 최대값을 골라 (2, 2) 크기의 출력을 만든다.\\n특성 맵이 여러 개라면 동일한 작업을 반복한다.\\n즉 10개의 특성 맵이 있다면 풀링을 거친 특성 맵도 10개가 된다. (10번 반복 수행)\\n\\n* 풀링 층의 출력도 특성 맵이라고 하는가?\\n  - 그렇다. 합성곱 신경망에서는 합성곱 층과 풀링 층에서 출력되는 값을 모두 특성 맵이라 부른다.\\n\\n눈여겨볼 점은 풀링 영역이 두 칸씩 이동했다는 점이다.\\n합성곱에서는 커널이 한 칸씩 이동했기 때문에 겹치는 부분이 있었다.\\n하지만 풀링에서는 겹치지 않고 이동한다.\\n따라서 풀리의 크기가 (2, 2)이면 가로 세로 두 칸씩 이동한다.\\n즉 스트라이드가 2이다.\\n(3, 3) 풀링이면 가로 세로 세 칸씩 이동한다.\\n\\n풀링은 가중치가 없고 풀링 크기와 스트라이드가 같기 때문에 이해하기 쉽다.\\n또 패딩이 없다.\\n케라스에서는 MaxPooling2D 클래스로 풀링을 수행할 수 있다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.MaxPooling2D(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GiLQk6SlbV3",
        "outputId": "79bf96b8-2989-4e85-cc4e-35f251629977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MaxPooling2D name=max_pooling2d_2, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MaxPooling2D의 첫 번째 매개변수로 풀링의 크기를 지정한다.\n",
        "대부분 풀링의 크기는 2이다.\n",
        "즉 가로 세로 크기를 절반으로 줄인다.\n",
        "가로 세로 방향의 풀링 크기를 다르게 하려면 첫 번째 매개변수를 정수의 튜플로 지정할 수 있다. (ex. (2, 3))\n",
        "그러나 이런 경우는 극히 드물다.\n",
        "\n",
        "합성곱 층과 마찬가지로 strides와 padding 매개변수를 제공한다.\n",
        "strides의 기본값은 자동으로 풀링의 크기이므로 따로 지정할 필요가 없다!\n",
        "padding의 기본값은 'valid'로 패딩을 하지 않는다.\n",
        "앞서 언급한 대로 풀링은 패딩을 하지 않기 때문에 이 매개변수를 바꾸는 경우는 거의 없다.\n",
        "예를 들어 바로 이전에 쓴 최대 풀링과 같은 코드는 다음과 같다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qf7xpRtGlf3o",
        "outputId": "7bb7629b-1a45-4953-c555-a950cc8f0eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nMaxPooling2D의 첫 번째 매개변수로 풀링의 크기를 지정한다.\\n대부분 풀링의 크기는 2이다.\\n즉 가로 세로 크기를 절반으로 줄인다.\\n가로 세로 방향의 풀링 크기를 다르게 하려면 첫 번째 매개변수를 정수의 튜플로 지정할 수 있다. (ex. (2, 3))\\n그러나 이런 경우는 극히 드물다.\\n\\n합성곱 층과 마찬가지로 strides와 padding 매개변수를 제공한다.\\nstrides의 기본값은 자동으로 풀링의 크기이므로 따로 지정할 필요가 없다!\\npadding의 기본값은 'valid'로 패딩을 하지 않는다.\\n앞서 언급한 대로 풀링은 패딩을 하지 않기 때문에 이 매개변수를 바꾸는 경우는 거의 없다.\\n예를 들어 바로 이전에 쓴 최대 풀링과 같은 코드는 다음과 같다.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.MaxPooling2D(2, strides=2, padding='valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOtFjqp5me7C",
        "outputId": "074c3271-c487-478d-8d47-a048888f7650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MaxPooling2D name=max_pooling2d_3, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "평균 풀링을 제공하는 클래스는 AveragePooling2D이다.\n",
        "최댓값 대신 평균을 계산하는 것만 빼면 MaxPooling2D와 동일하며 제공하는 매개변수도 같다.\n",
        "많은 경우 평균 풀링보다 최대 풀링을 많이 사용한다.\n",
        "평균 풀링은 특성 맵에 있는 중요한 정보를 (평균하여) 희석시킬 수 있기 때문이다.\n",
        "\n",
        "꼭 기억할 점은 풀링은 가로 세로 방향으로만 진행한다!\n",
        "특성 맵의 개수는 변하지 않고 그대로이다!\n",
        "이제 합성곱의 중요한 모든 요소를 배웠다.\n",
        "합성곱 신경망의 전체 구조를 살표보자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xJKvjDr3mjgY",
        "outputId": "4cdfe305-0e5a-4e67-f5d6-9e66d0624ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n평균 풀링을 제공하는 클래스는 AveragePooling2D이다.\\n최댓값 대신 평균을 계산하는 것만 빼면 MaxPooling2D와 동일하며 제공하는 매개변수도 같다.\\n많은 경우 평균 풀링보다 최대 풀링을 많이 사용한다.\\n평균 풀링은 특성 맵에 있는 중요한 정보를 (평균하여) 희석시킬 수 있기 때문이다.\\n\\n꼭 기억할 점은 풀링은 가로 세로 방향으로만 진행한다!\\n특성 맵의 개수는 변하지 않고 그대로이다!\\n이제 합성곱의 중요한 모든 요소를 배웠다.\\n합성곱 신경망의 전체 구조를 살표보자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **합성곱 신경망의 전체 구조**"
      ],
      "metadata": {
        "id": "FuXhUjYQnaUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "합성곱 신경망은 합성곱 층(세임 or 밸리드 패딩), 풀링층, 밀집층의 순서의 구조를 가진다.\n",
        "풀링을 사용하는 이유는 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다\n",
        "풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문이다.\n",
        "합성곱 신경망은 이렇게 합성곱 층에서 특성맵을 생성하고 풀링에서 크기를 줄이는 구조가 쌍을 이룬다.\n",
        "\n",
        "풀링까지 거친 특성 맵의 크기는 절반으로 줄었을 것이다.\n",
        "밀집층인 출력층에 이를 전달하려면 1차원 배열로 펼쳐야 한다. (7장에서의 Flatten 클래스)\n",
        "이제 이 배열은 n개의 원소를 가진 1차원 배열이고 출력층의 입력이 된다.\n",
        "\n",
        "출력층에는 3개의 뉴런을 두었다.\n",
        "즉 3개의 클래스를 분류하는 다중 분류 문제이다.\n",
        "출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 된다.\n",
        "\n",
        "다음 장에서 케라스로 직접 합성곱 신경망을 구현해보면 이 장에서 배운 내용을 더 잘 이해할 수 있을 것이다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "1i7viPgYncTL",
        "outputId": "77aa8965-26df-407e-cbc8-7d245cd8cafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n합성곱 신경망은 합성곱 층(세임 or 밸리드 패딩), 풀링층, 밀집층의 순서의 구조를 가진다.\\n풀링을 사용하는 이유는 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다\\n풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문이다.\\n합성곱 신경망은 이렇게 합성곱 층에서 특성맵을 생성하고 풀링에서 크기를 줄이는 구조가 쌍을 이룬다.\\n\\n풀링까지 거친 특성 맵의 크기는 절반으로 줄었을 것이다.\\n밀집층인 출력층에 이를 전달하려면 1차원 배열로 펼쳐야 한다. (7장에서의 Flatten 클래스)\\n이제 이 배열은 n개의 원소를 가진 1차원 배열이고 출력층의 입력이 된다.\\n\\n출력층에는 3개의 뉴런을 두었다.\\n즉 3개의 클래스를 분류하는 다중 분류 문제이다.\\n출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 된다.\\n\\n다음 장에서 케라스로 직접 합성곱 신경망을 구현해보면 이 장에서 배운 내용을 더 잘 이해할 수 있을 것이다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **컬러 이미지를 사용한 합성곱**"
      ],
      "metadata": {
        "id": "NRgtZdvyuDQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "지금까지 나는 입력을 2차원 배열이라 가정했다.\n",
        "이 장에서 다룰 패션 MNIST 데이터는 실제로 흑백 이미지이기 때문에 2차원 배열로 표현 가능하다. (black or white 픽셀값만 존재)\n",
        "하지만 컬러 이미지라면 어떨까?\n",
        "컬러 이미지는 RGB 채널로 구성되어 있기에 컴퓨터는 이를 3차원 배열로 표시한다. (너비, 높이, 깊이)\n",
        "\n",
        "하나의 컬러 이미지는 너비와 높이 차원 외에 깊이 차원(또는 채널 차원)이 있다.\n",
        "예를 들어 앞의 예제에서 입력이 (4, 4)가 아니라 (4, 4, 3)이 되는 것이다.\n",
        "마지막 3이 깊이 차원이다.\n",
        "이런 경우에는 어떻게 합성곱이 수행될까?\n",
        "\n",
        "깊이가 있는 입력에서 합성곱을 수행하기 위해서는 도장도 깊이가 필요하다.(실제로 이런 도장은 없지만 상상해보자)\n",
        "즉 필터의 커널 크기가 (3, 3)이 아니라 (3, 3, 3)이 된다.\n",
        "커널 배열의 깊이는 항상 입력의 깊이와 같다.\n",
        "\n",
        "이 합성곱의 계산은 (3, 3, 3) 영역에 해당하는 27개의 원소에 27개의 가중치를 곱하고 절편을 더하는 식이 된다.\n",
        "기본적으로 2차원 합성곱과 같지만 도장이 입력의 깊이만큼 쑥 들어간다고 생각해 보자.\n",
        "\n",
        "여기서 중요한 것은 입력이나 필터의 차원이 몇 개인지 상관없이 항상 출력은 하나의 값이라는 점이다!\n",
        "즉 특성 맵에 있는 한 원소가 채워진다.\n",
        "\n",
        "사실 케라스의 합성곱 층은 항상 이렇게 3차원 입력을 기대한다.\n",
        "만약 패션 MNIST 데이터처럼 흑백 이미지일 경우에는 깊이 차원이 1인 3차원 배열로 변환하여 전달한다.\n",
        "\n",
        "예를 들어 (28, 28) 크기의 2차원 배열을 (28, 28, 1) 크기의 3차원 배열로 변환한다.\n",
        "원소 개수는 동일하면서 차원만 맞춘 셈이다.\n",
        "\n",
        "이와 비슷한 경우가 또 있다.\n",
        "합성곱 층-풀링 층 다음에 다시 또 합성곱 층이 올 때이다.\n",
        "예를 들어 첫 번째 합성곱 층의 필터 개수가 5개라고 가정하여\n",
        "첫 번째 풀링 층을 통과한 특성 맵의 크기가 (4, 4, 5)라고 해보자.\n",
        "\n",
        "두 번째 합성곱 층에서 필터의 너비와 높이가 각각 3이라면 이 필터의 커널 크기는 (3, 3, 5)가 된다.\n",
        "왜냐하면 입력의 깊이와 필터의 깊이는 같아야 하기 때문이다.\n",
        "45(=3 * 3* 5)개의 가중치를 곱하고 절편을 더한 이 합성곱의 결과는 1개의 출력을 만든다.\n",
        "\n",
        "두 번째 합성곱 층의 필터 개수가 10개라면 만들어진 특성 맵의 크기는 (2, 2, 10)이 될 것이다.\n",
        "이렇게 합성곱 신경망은 너비와 높이는 점점 줄어들고 깊이는 점점 깊어지는 것이 특징이다!\n",
        "그리고 마지막에 출력층 전에 특성 맵을 모두 펼쳐서 밀집층의 입력으로 사용한다.\n",
        "\n",
        "합성곱 신경망에서 필터는 이미지에 있는 어떤 특징을 찾는다고 생각할 수 있다.\n",
        "처음에는 간단한 기본적인 특징(직선, 곡선 등)을 찾고\n",
        "층이 깊어질수록 다양하고 구체적인 특징을 감지할 수 있도록 필터의 개수를 늘린다.\n",
        "또 어떤 특징이 이미지의 어느 위치에 놓이더라도 쉽게 감지할 수 있도록 너비와 높이 차원을 점점 줄여가는 것이다.\n",
        "\n",
        "다음 장에서는 텐서플로와 케라스 API로 실제 합성곱 신경망을 만들어 보겠다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "YKgs65oFuFZ7",
        "outputId": "d4cc0335-6c13-4a10-901d-6b7a77d036a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n지금까지 나는 입력을 2차원 배열이라 가정했다.\\n이 장에서 다룰 패션 MNIST 데이터는 실제로 흑백 이미지이기 때문에 2차원 배열로 표현 가능하다. (black or white 픽셀값만 존재)\\n하지만 컬러 이미지라면 어떨까?\\n컬러 이미지는 RGB 채널로 구성되어 있기에 컴퓨터는 이를 3차원 배열로 표시한다. (너비, 높이, 깊이)\\n\\n하나의 컬러 이미지는 너비와 높이 차원 외에 깊이 차원(또는 채널 차원)이 있다.\\n예를 들어 앞의 예제에서 입력이 (4, 4)가 아니라 (4, 4, 3)이 되는 것이다.\\n마지막 3이 깊이 차원이다.\\n이런 경우에는 어떻게 합성곱이 수행될까?\\n\\n깊이가 있는 입력에서 합성곱을 수행하기 위해서는 도장도 깊이가 필요하다.(실제로 이런 도장은 없지만 상상해보자)\\n즉 필터의 커널 크기가 (3, 3)이 아니라 (3, 3, 3)이 된다.\\n커널 배열의 깊이는 항상 입력의 깊이와 같다.\\n\\n이 합성곱의 계산은 (3, 3, 3) 영역에 해당하는 27개의 원소에 27개의 가중치를 곱하고 절편을 더하는 식이 된다.\\n기본적으로 2차원 합성곱과 같지만 도장이 입력의 깊이만큼 쑥 들어간다고 생각해 보자.\\n\\n여기서 중요한 것은 입력이나 필터의 차원이 몇 개인지 상관없이 항상 출력은 하나의 값이라는 점이다!\\n즉 특성 맵에 있는 한 원소가 채워진다.\\n\\n사실 케라스의 합성곱 층은 항상 이렇게 3차원 입력을 기대한다.\\n만약 패션 MNIST 데이터처럼 흑백 이미지일 경우에는 깊이 차원이 1인 3차원 배열로 변환하여 전달한다.\\n\\n예를 들어 (28, 28) 크기의 2차원 배열을 (28, 28, 1) 크기의 3차원 배열로 변환한다.\\n원소 개수는 동일하면서 차원만 맞춘 셈이다.\\n\\n이와 비슷한 경우가 또 있다.\\n합성곱 층-풀링 층 다음에 다시 또 합성곱 층이 올 때이다.\\n예를 들어 첫 번째 합성곱 층의 필터 개수가 5개라고 가정하여\\n첫 번째 풀링 층을 통과한 특성 맵의 크기가 (4, 4, 5)라고 해보자.\\n\\n두 번째 합성곱 층에서 필터의 너비와 높이가 각각 3이라면 이 필터의 커널 크기는 (3, 3, 5)가 된다.\\n왜냐하면 입력의 깊이와 필터의 깊이는 같아야 하기 때문이다.\\n45(=3 * 3* 5)개의 가중치를 곱하고 절편을 더한 이 합성곱의 결과는 1개의 출력을 만든다.\\n\\n두 번째 합성곱 층의 필터 개수가 10개라면 만들어진 특성 맵의 크기는 (2, 2, 10)이 될 것이다.\\n이렇게 합성곱 신경망은 너비와 높이는 점점 줄어들고 깊이는 점점 깊어지는 것이 특징이다!\\n그리고 마지막에 출력층 전에 특성 맵을 모두 펼쳐서 밀집층의 입력으로 사용한다.\\n\\n합성곱 신경망에서 필터는 이미지에 있는 어떤 특징을 찾는다고 생각할 수 있다.\\n처음에는 간단한 기본적인 특징(직선, 곡선 등)을 찾고 \\n층이 깊어질수록 다양하고 구체적인 특징을 감지할 수 있도록 필터의 개수를 늘린다.\\n또 어떤 특징이 이미지의 어느 위치에 놓이더라도 쉽게 감지할 수 있도록 너비와 높이 차원을 점점 줄여가는 것이다.\\n\\n다음 장에서는 텐서플로와 케라스 API로 실제 합성곱 신경망을 만들어 보겠다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}