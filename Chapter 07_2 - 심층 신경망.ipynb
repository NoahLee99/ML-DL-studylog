{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN990L0GkFP4gaDNSqBoXCF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahLee99/ML-DL-studylog/blob/main/Chapter%2007-2%20-%20%EC%8B%AC%EC%B8%B5%20%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "fNas0gxQRv6U",
        "outputId": "6b9d957a-7a5e-492d-8a49-90fbbd604ede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n이전 장에서 성공적으로 로지스틱 회귀보다 성능이 좋은 인공 신경망을 만들었다.\\n이제 이 인공 신경망의 성능을 더욱 높여보자.\\n\\n다시 케라스 API를 사용해 패션 MNIST 데이터셋을 불러오겠다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "키워드 = [심층 신경망, 렐루 함수, 옵티마이저]\n",
        "- 심층 신경망: 2개 이상의 층을 포함한 신경망이다.\n",
        "               종종 다층 인공 신경망, 심층 신경망, 딥러닝을 같은 의미로 사용한다.\n",
        "- 렐루 함수: 이미지 분류 모델의 은닉층에 많이 사용되는 활성화 함수이다.\n",
        "             시그모이드 함수는 층이 많을수록 활성화 함수의 양쪽 끝에서 변화가 작기 때문에 학습이 어려워진다.\n",
        "             렐루 함수는 이런 문제가 없으며 계산도 간단하다.\n",
        "- 옵티마이저: 신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법을 말한다.\n",
        "              케라스에는 다양한 경사 하강법 알고리즘이 구현되어 있다.\n",
        "              대표적으로 SGD, 네스테로프 모멘텀, RMSprop, Adam 등이 있다.\n",
        "\n",
        "핵심 패키지 및 함수: [add(), summary(), SGD, Adagrad, RMSprop, Adam]\n",
        "- add(): 케라스 모델에 층을 추가하는 메서드이다.\n",
        "         이 메서드는 keras.layers 패키지 아래에 있는 층의 객체를 입력받아 신경망 모델에 추가한다.\n",
        "         add() 메서드를 호출하여 전달한 순서대로 층이 차례대로 늘어난다.\n",
        "- summary(): 케라스 모델의 정보를 출력하는 메서드이다. (pandas의 info()와 같은 기능)\n",
        "             모델에 추가된 층의 종류와 순서, 모델 파라미터 개수를 출력한다.\n",
        "             층을 만들 때 name 매개변수로 이름을 지정하면 summary() 메서드 출력에서 구분하기 쉽다.\n",
        "- SGD: 기본 경사 하강법 옵티마이저 클래스이다.\n",
        "       learnin_rate 매개변수로 학습률을 지정하며 기본값은 0.01이다.\n",
        "       momentum 매개변수에 0 이상의 값을 지정하면 모멘텀 최적화를 수행한다.\n",
        "       nesterov 매개변수를 True로 지정하면 네스테로프 모멘텀 최적화를 수행한다.\n",
        "- Adagrad: Adagrad 옵티마이저 클래스이다.\n",
        "           learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001이다.\n",
        "           Adagrad는 그레이디언트 제곱을 누적하여 학습률을 나눈다.\n",
        "           initial_accumulator_value 매개변수에서 누적 초깃값을 지정할 수 있으며 기본값은 0.1이다.\n",
        "- RMSprop: RMSprop 옵티마이저 클래스이다.\n",
        "           learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001이다.\n",
        "           Adagrad처럼 그레이디언트 제곱으로 학습률을 나누지만 최근의 그레이디언트를 사용하기 위해 지수 감소를 사용한다.\n",
        "           rho 매개변수에서 감소 비율을 지정하며 기본값은 0.9이다.\n",
        "- Adam: Adam 옵티마이저 클래스이다.\n",
        "        learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001이다.\n",
        "        모멘텀 최적화에 있는 그레이디언트 지수 감소 평균을 조절하기 위해 beta_1 매개변수가 있으며 기본값은 0.9이다.\n",
        "        RMSprop에 있는 그레이디언트 제곱의 지수 감소 평균을 조절하기 위해 beta_2 매개변수가 있으며 기본값은 0.999이다.\n",
        "\n",
        "\n",
        "이전 장에서 성공적으로 로지스틱 회귀보다 성능이 좋은 인공 신경망을 만들었다.\n",
        "이제 이 인공 신경망의 성능을 더욱 높여보자.\n",
        "\n",
        "다시 케라스 API를 사용해 패션 MNIST 데이터셋을 불러오겠다.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "emS3B-tWS7Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드\n",
        "from tensorflow import keras\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0xNuneoSin2",
        "outputId": "e3a412b3-5297-490a-a774-ebd017b94c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "그다음 이미지의 픽셀값을 0~255 범위에서 0~1 사이로 변환하고,\n",
        "28 x 28 크기의 2차원 배열을 784 크기의 1차원 배열로 펼칩니다.\n",
        "마지막으로 사이킷런의 train_test_split() 함수로 훈련 세트와 검증 세트로 나눈다.\n",
        "이 과정까지는 07-1 장에서 했던 것과 동일하다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "7aR-UuiDTNvX",
        "outputId": "45af71f1-54df-4131-9aca-434e4dc8a3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n그다음 이미지의 픽셀값을 0~255 범위에서 0~1 사이로 변환하고,\\n28 x 28 크기의 2차원 배열을 784 크기의 1차원 배열로 펼칩니다.\\n마지막으로 사이킷런의 train_test_split() 함수로 훈련 세트와 검증 세트로 나눈다.\\n이 과정까지는 07-1 장에서 했던 것과 동일하다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 1차원 배열로 변환 및 데이터 세트 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled = train_input / 255.0 # 입력 데이터 정규화 (모든 픽셀값을 0~1 사이로 변환)\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "8wIEAGw5Tyrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src='https://velog.velcdn.com/images/simon919/post/48fbc91e-edd2-4d10-acff-684f670dff83/image.png'width='780'\n",
        "height = '600' /><br>\n",
        "</center>\n",
        "\n",
        "<!-- source: https://velog.io/@simon919/7-2.-%EC%8B%AC%EC%B8%B5-%EC%8B%A0%EA%B2%BD%EB%A7%9D -->"
      ],
      "metadata": {
        "id": "uCnouPJsZREW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "example)\n",
        "간단한 심층 신경망 모델을 예로 들어보겠습니다.\n",
        "\n",
        "입력층: 이미지 데이터 (픽셀 값)\n",
        "은닉층: 100개의 뉴런, ReLU 활성화 함수 사용\n",
        "출력층: 10개의 뉴런 (10개의 클래스), softmax 활성화 함수 사용\n",
        "이 모델에서 데이터는 다음과 같은 과정을 거칩니다.\n",
        "\n",
        "입력 데이터가 은닉층에 입력됩니다.\n",
        "은닉층의 각 뉴런은 입력 데이터에 가중치를 곱하고 편향을 더한 후, ReLU 활성화 함수를 적용하여 출력값을 생성합니다.\n",
        "은닉층의 출력값은 출력층에 입력됩니다.\n",
        "출력층의 각 뉴런은 은닉층의 출력값에 가중치를 곱하고 편향을 더한 후,\n",
        " softmax 활성화 함수를 적용하여 최종 예측 값 (각 클래스에 속할 확률)을 생성합니다.\n",
        " '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "wOwLTCEFDDeo",
        "outputId": "b0f8fb34-da86-428b-be94-53e56445808e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nexample)\\n간단한 심층 신경망 모델을 예로 들어보겠습니다.\\n\\n입력층: 이미지 데이터 (픽셀 값)\\n은닉층: 100개의 뉴런, ReLU 활성화 함수 사용\\n출력층: 10개의 뉴런 (10개의 클래스), softmax 활성화 함수 사용\\n이 모델에서 데이터는 다음과 같은 과정을 거칩니다.\\n\\n입력 데이터가 은닉층에 입력됩니다.\\n은닉층의 각 뉴런은 입력 데이터에 가중치를 곱하고 편향을 더한 후, ReLU 활성화 함수를 적용하여 출력값을 생성합니다.\\n은닉층의 출력값은 출력층에 입력됩니다.\\n출력층의 각 뉴런은 은닉층의 출력값에 가중치를 곱하고 편향을 더한 후,\\n softmax 활성화 함수를 적용하여 최종 예측 값 (각 클래스에 속할 확률)을 생성합니다.\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "이전 장에서 만든 신경망 모델과 다른 점은 입력층과 출력층 사이에 밀집층이 추가된 것이다.\n",
        "이렇게 입력층과 출력층 사이에 있는 모든 층을 \"은닉층(hidden layer)\"이라 부른다.\n",
        "\n",
        "은닉층에는 주황색 원으로 활성화 함수가 표시되어 있다.\n",
        "활성화 함수는 신경망 층의 선형 방정식의 계산 값에 적용하는 함수이다.\n",
        "이전 장에서 출력층에 적용했던 소프트맥스도 활성화 함수이다.\n",
        "출력층에 적용하는 활성화 함수는 종류가 제한되어 있는데,\n",
        "이진 분류일 경우 시그모이드 함수를 사용하고 다중 분류일 경우 소프트맥스 함수를 사용한다.\n",
        "이에 비해 은닉층의 활성화 함수는 비교적 자유롭다.\n",
        "대표적으로 시그모이드 함수와 잠시 후에 볼 \"렐루(ReLU)\" 함수 등을 사용한다.\n",
        "\n",
        "회귀를 위한 신경망의 출력층에서는 어떤 활성화 함수를 사용할까? (분류는 시그모이드 or 소프트맥스)\n",
        "분류 문제는 클레스에 대한 확률을 출력하기 위해 활성화 함수를 사용한다.\n",
        "회귀의 출력은 임의의 어떤 숫자이므로 활성화 함수를 적용할 필요가 없다.\n",
        "즉 출력층의 선형 방정식의 계산을 그대로 출력한다.\n",
        "이렇게 하려면 Dense 층의 activatin 매개변수에 아무런 값을 지정하지 않는다.\n",
        "\n",
        "그런데 은닉층에 왜 활성화 함수를 적용할까?\n",
        "아래에 있는 2개의 선형 방정식을 생각해 보자.\n",
        "a * 4 + 2 = b\n",
        "                --> a * 12 + 1 = c\n",
        "b  * 3 - 5 = c\n",
        "\n",
        "왼쪽의 첫 번째 식에서 계산된 b가 두 번째 식에서 c를 계산하기 위해 쓰인다.\n",
        "하지만 두 번째 식에 첫 번째 식을 대입하면 오른쪽처럼 하나로 합쳐질 수 있다.\n",
        "이렇게 되면 b는 사라지고, b가 하는 일이 없는 셈이다.\n",
        "\n",
        "신경망도 마찬가지이다.\n",
        "은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없는 셈이다.\n",
        "선형 계산을 적당하게 비선형적으로 비틀어 주어야 한다.\n",
        "그래야 다음 층의 계산과 단순히 합쳐지지 않고 나름의 역할을 할 수 있다.\n",
        "마치 다음과 같다.\n",
        "a * 4 + 2 = b\n",
        "log(b) = k\n",
        "k * 3 - 5 = c\n",
        "\n",
        "다른 책에서 보니 인공 신경망 그림에 활성화 함수가 없던데?\n",
        "인공 신경망을 그림으로 나타낼 때 활성화 함수를 생략하는 경우가 많은데\n",
        "이는 절편과 마찬가지로 번거로움을 피하기 위해 활성화 함수를 별개의 층으로 생각하지 않고\n",
        "층에 포함되어 있다고 간주하기 때문이다.\n",
        "그림에서 보이지는 않지만 모든 신경망의 은닉층에는 항상 활성화 함수가 있다!\n",
        "\n",
        "많이 사용하는 활성화 함수 중 하나는 4장에서 배운 시그모이드 함수이다.\n",
        "기억을 되살리기 위해 다시 한번 살펴보겠다.\n",
        "σ(x) = 1 / (1 + exp^-z)\n",
        "\n",
        "이 함수는 뉴런의 출력 z값을 0과 1사이로 압축한다.\n",
        "그럼 시그모이드 활성화 함수를 사용한 은닉층과\n",
        "소프트맥스 함수를 사용한 출력층을 케라스의 Dense 클래스로 만들어 보겠다.\n",
        "이전 장에서 언급했듯이 케라스에서 신경망의 첫 번째 층은 input_shape 매개변수로 입력의 크기를 꼭 지정해 주어야 한다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "eXC9FctHUgCU",
        "outputId": "31347c12-2a08-4474-eed4-2fe86719cc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n이전 장에서 만든 신경망 모델과 다른 점은 입력층과 출력층 사이에 밀집층이 추가된 것이다.\\n이렇게 입력층과 출력층 사이에 있는 모든 층을 \"은닉층(hidden layer)\"이라 부른다.\\n\\n은닉층에는 주황색 원으로 활성화 함수가 표시되어 있다.\\n활성화 함수는 신경망 층의 선혀 방정식의 계산 값 적용하는 함수이다.\\n이전 장에서 출력층에 적용했던 소프트맥스도 활성화 함수이다.\\n출력층에 적용하는 활성화 함수는 종류가 제한되어 있는데,\\n이진 분류일 경우 시그모이드 함수를 사용하고 다중 분류일 경우 소프트맥스 함수를 사용한다.\\n이에 비해 은닉층의 활성화 함수는 비교적 자유롭다.\\n대표적으로 시그모이드 함수와 잠시 후에 볼 \"렐루(ReLU)\" 함수 등을 사용한다.\\n\\n회귀를 위한 신경망의 출력층에서는 어떤 활성화 함수를 사용할까? (분류는 시그모이드 or 소프트맥스)\\n분류 문제는 클레스에 대한 확률을 출력하기 위해 활성화 함수를 사용한다.\\n회귀의 출력은 임의의 어떤 숫자이므로 활성화 함수를 적용할 필요가 없다.\\n즉 출력층의 선형 방정식의 계산을 그대로 출력한다.\\n이렇게 하려면 Dense 층의 activatin 매개변수에 아무런 값을 지정하지 않는다.\\n\\n그런데 은닉층에 왜 활성화 함수를 적용할까?\\n아래에 있는 2개의 선형 방정식을 생각해 보자.\\na * 4 + 2 = b \\n                --> a * 12 + 1 = c\\nb  * 3 - 5 = c\\n\\n왼쪽의 첫 번째 식에서 계산된 b가 두 번째 식에서 c를 계산하기 위해 쓰인다.\\n하지만 두 번째 식에 첫 번째 식을 대입하면 오른쪽처럼 하나로 합쳐질 수 있다.\\n이렇게 되면 b는 사라지고, b가 하는 일이 없는 셈이다.\\n\\n신경망도 마찬가지이다.\\n은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없는 셈이다.\\n선형 계산을 적당하게 비선형적으로 비틀어 주어야 한다.\\n그래야 다음 층의 계산과 단순히 합쳐지지 않고 나름의 역할을 할 수 있다.\\n마치 다음과 같다.\\na * 4 + 2 = b\\nlog(b) = k\\nk * 3 - 5 = c\\n\\n다른 책에서 보니 인공 신경망 그림에 활성화 함수가 없던데?\\n인공 신경망을 그림으로 나타낼 때 활성화 함수를 생략하는 경우가 많은데 \\n이는 절편과 마찬가지로 번거로움을 피하기 위해 활성화 함수를 별개의 층으로 생각하지 않고\\n층에 포함되어 있다고 간주하기 때문이다.\\n그림에서 보이지는 않지만 모든 신경망의 은닉층에는 항상 활성화 함수가 있다!\\n\\n많이 사용하는 활성화 함수 중 하나는 4장에서 배운 시그모이드 함수이다.\\n기억을 되살리기 위해 다시 한번 살펴보겠다.\\nσ(x) = 1 / (1 + exp^-z)\\n\\n이 함수는 뉴런의 출력 z값을 0과 1사이로 압축한다.\\n그럼 시그모이드 활성화 함수를 사용한 은닉층과 \\n소프트맥스 함수를 사용한 출력층을 케라스의 Dense 클래스로 만들어 보겠다.\\n이전 장에서 언급했듯이 케라스에서 신경망의 첫 번째 층은 input_shape 매개변수로 입력의 크기를 꼭 지정해 주어야 한다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력층을 Dense 클래스로 생성\n",
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784, )) # Dense의 첫 번째 인자는 뉴런의 개수임을 기억하자\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "2JZRO1N6lTy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "dense1이 은닉층이고 100개의 뉴런을 가진 밀집층이다.\n",
        "활성화 함수를 'sigmoid'라고 지정했고 input_shape 매개변수에서 입력의 크기를 (784, )로 지정했다.\n",
        "은닉층의 뉴런 개수를 정하는 데는 특별한 기준이 없다.\n",
        "몇 개의 뉴런을 두어야 할지 판단하기 위해서는 상당한 경험이 필요하다.\n",
        "\n",
        "여기에 한 가지 제약 사항이 있다면 적어도 출력층의 뉴런보다는 많게 만들어야 한다. (중요)\n",
        "클래스 10개에 대한 확률을 에측해야 하는데 이전 은닉층의 뉴런이 10개보다 적다면 부족한 정보가 전달된 것이다.\n",
        "\n",
        "그다음 dense2는 출력층이다.\n",
        "10개의 클래스를 분류하므로 10개의 뉴런을 두었고 활성화 함수는 소프트맥스 함수로 지정했다.\n",
        "\n",
        "이제 앞에서 만든 dense1과 dense2 객체를 Sequential 클래스에 추가하여 \"심층 신경망(deep neural network, DNN)\"을 만들어 보자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "5D8NxNl2rVUj",
        "outputId": "851364cf-ca60-4c3a-b4ec-5ce99326276c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndense1이 은닉층이고 100개의 뉴런을 가진 밀집층이다.\\n활성화 함수를 \\'sigmoid\\'라고 지정했고 input_shape 매개변수에서 입력의 크기를 (784, )로 지정했다.\\n은닉층의 뉴런 개수를 정하는 데는 특별한 기준이 없다.\\n몇 개의 뉴런을 두어야 할지 판단하기 위해서는 상당한 경험이 필요하다.\\n\\n여기에 한 가지 제약 사항이 있다면 적어도 출력층의 뉴런보다는 많게 만들어야 한다.\\n클래스 10개에 대한 확률을 에측해야 하는데 이전 은닉층의 뉴런이 10개보다 적다면 부족한 정보가 전달된 것이다.\\n\\n그다음 dense2는 출력층이다.\\n10개의 클래스를 분류하므로 10개의 뉴런을 두었고 활성화 함수는 소프트맥스 함수로 지정했다.\\n\\n이제 앞에서 만든 dense1과 dense2 객체를 Sequential 클래스에 추가하여 \"심층 신경망(deep neural network, DNN)\"을 만들어 보자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential 클래스에 dense 객체 추가 (DNN 모델 생성)\n",
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "k0IKCt_Qxd2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Sequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 이와 같이 dense1과 dense2를 리스트로 만들어 전달한다.\n",
        "여기서 주의할 것은 출력층을 가장 마지막에 두어야 한다는 것이다.\n",
        "이 리스트는 가장 처음 등장하는 은닉층에서 마지막 출력층의 순서로 나열해야 한다.\n",
        "\n",
        "인공 신경망의 강력한 성능은 바로 이렇게 층을 추가하여 입력 데이터에 대해 연속적인 학습을 진행하는 능력에서 나온다.\n",
        "앞 장들에서 배운 선형 회귀, 로지스틱 회귀, 결정 트리 등 다른 머신러닝 알고리즘들과 대조된다.\n",
        "물론 2개 이상의 층을 추가할 수도 있다.\n",
        "다음 장에서 더 복잡한 모델을 만들어 보겠다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "YBrHkz2axwsW",
        "outputId": "e3fd598e-c753-48d7-c870-eac60e1d7e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 이와 같이 dense1과 dense2를 리스트로 만들어 전달한다.\\n여기서 주의할 것은 출력층을 가장 마지막에 두어야 한다는 것이다.\\n이 리스트는 가장 처음 등장하는 은닉층에서 마지막 출력층의 순서로 나열해야 한다.\\n\\n인공 신경망의 강력한 성능은 바로 이렇게 층을 추가하여 입력 데이터에 대해 연속적인 학습을 진행하는 능력에서 나온다.\\n앞 장들에서 배운 선형 회귀, 로지스틱 회귀, 결정 트리 등 다른 머신러닝 알고리즘들과 대조된다.\\n물론 2개 이상의 층을 추가할 수도 있다.\\n다음 장에서 더 복잡한 모델을 만들어 보겠다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 층에 대한 정보 확인\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "jsMJ12wQzFGn",
        "outputId": "7a08d154-85df-485b-da89-e1416d8e0940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "맨 첫 줄에 모델의 이름이 나오고, 그다음 이 모델에 들어 있는 층이 순서대로 나열된다.\n",
        "이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서대로 나열된다.\n",
        "\n",
        "층마다 층 이름, 클래스, 출력  크기, 모델 파라미터 개수가 출력된다.\n",
        "층을 만들 때 name 매개변수로 이름을 지정할 수 있다.\n",
        "층 이름을 지정하지 않으면 케라스가 자동으로 'dense'라고 이름을 붙인다.\n",
        "\n",
        "출력 크기를 보면 (None, 100)이다.\n",
        "첫 번째 차원은 샘플의 개수를 나타내는데, 아직 정의되어 있지 않아서 None이다.\n",
        "왜 그럴까?\n",
        "케라스 모델의 fit() 메서드에 훈련 데이터를 주입하면 이 데이터를 한 번에 모두 사용하지 않고\n",
        "잘게 나누어 여러 번에 걸쳐 경사 하강법 단계를 수행한다. 바로 미니배치 경사 하강법을 사용하는 것이다.\n",
        "\n",
        "케라스의 기본  미니배치 크기는 32개이다.\n",
        "이 값은 fit() 메서드에서 batch_size 매개변수로 바꿀 수 있다.\n",
        "따라서 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다.\n",
        "이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원이라고 부른다.\n",
        "\n",
        "두 번째 100은 쉽다.\n",
        "은닉층의 뉴런 개수를 100개로 두었으니 100개의 출력이 나온다.\n",
        "즉 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축되었다.\n",
        "\n",
        "마지막으로 모델 파라미터 개수가 출력된다.\n",
        "이 층은 Dense 층이므로 입력 픽셀 784개와 100개의 모든 조합에 대한 가중치가 있다.\n",
        "그리고 뉴런마다 1개의 절편이 있다.\n",
        "\n",
        "두 번째 층의 출력 크기는 (None, 10)이다.\n",
        "배치 차원은 동일하게 None이고 출력 뉴런 개수가 10개이기 때문이다.\n",
        "이 층의 모델 파라미터 개수는 몇 개일까?\n",
        "100개의 은닉층 뉴런과 10개의 출력층 뉴런이 모두 연결되고\n",
        "출력층의 뉴런마다 하나의 절편이 있기 때문에 총 1,010개의 모델 파라미터가 있다.\n",
        "\n",
        "summary() 메서드의 마지막에는 총 모델 파라미터 개수와 훈련되는 파라미터 개수가 동일하게 79,510으로 나온다.\n",
        "은닉층과 출력층의 파라미터 개수를 합친 값이다.\n",
        "그 아래 훈련되지 않는 파라미터(Non-trainable params)는 0으로 나온다.\n",
        "간혹 경사 하강법으로 훈련되지 않는 파라미터를 가진 층이 있다.\n",
        "이런 층의 파라미터 개수가 여기에 나타난다.\n",
        "\n",
        "모델을 훈련하기 전에 Sequential 클래스에 층을 추가하는 다른 방법을 알아보겠다.\n",
        "앞에서는 Dense 클래스의 객체 dense1, dense2를 만들어 Sequential 클래스에 전달했다.\n",
        "이 두 객체를 따로 저장하여 쓸 일이 없기 때문에 다음처럼 Seqeuntial 클래스의 생성자 안에서\n",
        "바로 Dense 클래스의 객체를 만드는 경우가 많다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "tD4bhUPezTkT",
        "outputId": "cf2da23c-f9dc-4e4a-d68c-d3ea9f7f03a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n맨 첫 줄에 모델의 이름이 나오고, 그다음 이 모델에 들어 있는 층이 순서대로 나열된다.\\n이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서대로 나열된다.\\n\\n층마다 층 이름, 클래스, 출력  크기, 모델 파라미터 개수가 출력된다.\\n층을 만들 때 name 매개변수로 이름을 지정할 수 있다. \\n층 이름을 지정하지 않으면 케라스가 자동으로 'dense'라고 이름을 붙인다.\\n\\n출력 크기를 보면 (None, 100)이다.\\n첫 번째 차원은 샘플의 개수를 나타내는데, 아직 정의되어 있지 않아서 None이다.\\n왜 그럴까?\\n케라스 모델의 fit() 메서드에 훈련 데이터를 주입하면 이 데이터를 한 번에 모두 사용하지 않고 \\n잘게 나누어 여러 번에 걸쳐 경사 하강법 단계를 수행한다. 바로 미니배치 경사 하강법을 사용하는 것이다.\\n\\n케라스의 기본  미니배치 크기는 32개이다.\\n이 값은 fit() 메서드에서 batch_size 매개변수로 바꿀 수 있다.\\n따라서 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다.\\n이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원이라고 부른다.\\n\\n두 번째 100은 쉽다.\\n은닉층의 뉴런 개수를 100개로 두었으니 100개의 출력이 나온다.\\n즉 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축되었다.\\n\\n마지막으로 모델 파라미터 개수가 출력된다.\\n이 층은 Dense 층이므로 입력 픽셀 784개와 100개의 모든 조합에 대한 가중치가 있다.\\n그리고 뉴런마다 1개의 절편이 있다.\\n\\n두 번째 층의 출력 크기는 (None, 10)이다.\\n배치 차원은 동일하게 None이고 출력 뉴런 개수가 10개이기 때문이다.\\n이 층의 모델 파라미터 개수는 몇 개일까?\\n100개의 은닉층 뉴런과 10개의 출력층 뉴런이 모두 연결되고 \\n출력층의 뉴런마다 하나의 절편이 있기 때문에 총 1,010개의 모델 파라미터가 있다.\\n\\nsummary() 메서드의 마지막에는 총 모델 파라미터 개수와 훈련되는 파라미터 개수가 동일하게 79,510으로 나온다.\\n은닉층과 출력층의 파라미터 개수를 합친 값이다.\\n그 아래 훈련되지 않는 파라미터(Non-trainable params)는 0으로 나온다.\\n간혹 경사 하강법으로 훈련되지 않는 파라미터를 가진 층이 있다.\\n이런 층의 파라미터 개수가 여기에 나타난다.\\n\\n모델을 훈련하기 전에 Sequential 클래스에 층을 추가하는 다른 방법을 알아보겠다.\\n앞에서는 Dense 클래스의 객체 dense1, dense2를 만들어 Sequential 클래스에 전달했다.\\n이 두 객체를 따로 저장하여 쓸 일이 없기 때문에 다음처럼 Seqeuntial 클래스의 생성자 안에서\\n바로 Dense 클래스의 객체를 만드는 경우가 많다.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')\n",
        "], name='패션 MNIST 모델')"
      ],
      "metadata": {
        "id": "oR_AJsdG5dAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "이렇게 작업하면 추가되는 층을 한눈에 쉽게 알아보는 장점이 있다.\n",
        "이전과 달리 이번에는 Sequential 클래스의 name 매개변수로 모델의 이름을 지정했다.\n",
        "또 Dense 층의 name 매개변수에 층의 이름을 'hidden'과 'output'으로 각각 지정했다.\n",
        "모델의 이름과 달리 층의 이름은 반드시 영문이어야 한다.\n",
        "summary() 메서드의 출력에 이름이 잘 반영되는지 확인해 보자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "YD_00ZlH53a4",
        "outputId": "37c03bf7-10e3-4007-9205-b65a777476c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n이렇게 작업하면 추가되는 층을 한눈에 쉽게 알아보는 장점이 있다.\\n이전과 달리 이번에는 Sequential 클래스의 name 매개변수로 모델의 이름을 지정했다.\\n또 Dense 층의 name 매개변수에 층의 이름을 'hidden'과 'output'으로 각각 지정했다.\\n모델의 이름과 달리 층의 이름은 반드시 영문이어야 한다.\\nsummary() 메서드의 출력에 이름이 잘 반영되는지 확인해 보자.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "PQ82z8SY6TUL",
        "outputId": "ede5e5e0-5cc6-4341-8dc1-e3380b09b6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"패션 MNIST 모델\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"패션 MNIST 모델\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ hidden (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "2개의 Dense 층이 이전과 동일하게 추가되었고 파라미터 개수도 같다.\n",
        "바뀐 것은 모델 이름과 층 이름이다.\n",
        "여러 모델과 많은 층을 사용할 때 name 매개변수를 사용하면 구분하기 쉽다.\n",
        "\n",
        "이 방법이 편리하지만 아주 많은 층을 추가하려면 Sequential 클래스 생성자가 매우 길어질 것이다.\n",
        "또 조건에 따라 층을 추가할 수도 없다.\n",
        "Sequential 클래스에서 층을 추가할 때 가장 널리 사용하는 방법은 모델의 add() 메서드이다.\n",
        "\n",
        "이 방법은 다음처럼 Sequential 클래스의 객체를 만들고 이 객체의 add() 메서드를 호출하여 층을 추가한다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "nadku5ie6X3M",
        "outputId": "d205fe20-bad3-4b57-d7da-803b79d545f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n2개의 Dense 층이 이전과 동일하게 추가되었고 파라미터 개수도 같다.\\n바뀐 것은 모델 이름과 층 이름이다.\\n여러 모델과 많은 층을 사용할 때 name 매개변수를 사용하면 구분하기 쉽다.\\n\\n이 방법이 편리하지만 아주 많은 층을 추가하려면 Sequential 클래스 생성자가 매우 길어질 것이다.\\n또 조건에 따라 층을 추가할 수도 없다.\\nSequential 클래스에서 층을 구가할 때 가장 널리 사용하는 방법은 모델의 add() 메서드이다.\\n\\n이 방법은 다음처럼 Sequential 클래스의 객체를 만들고 이 객체의 add() 메서드를 호출하여 층을 추가한다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Dense 클래스의 객체를 따로 변수에 담지 않고 바로 add() 메서드로 전달함"
      ],
      "metadata": {
        "id": "9F85YvJjJrvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "19jaX-oIKYE_",
        "outputId": "ba29a2e3-0dda-407c-f2e3-345f23748b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 본격적인 모델 훈련\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# 컴파일 단계에서는 옵티마이저, 손실 함수(loss), 평가 지표(metrics) 등을 설정함!\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k2BMCaAKz62",
        "outputId": "ee00edea-eabf-4a7e-b74a-1656d517338e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.7720\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.4270\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3857\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.3600\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.3410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c34f384d4b0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "훈련 세트에 대한 성능을 보면 추가된 층이 성능을 향상시켰다는 것을 잘 알 수 있다.\n",
        "인공 신경망에 몇 개의 층을 추가하더라도 compile() 메서드와 fit() 메서드의 사용법은 동일하다.\n",
        "이것이 케라스 API의 장점이다.\n",
        "\n",
        "다음은 이미지 분류 문제에서 높은 성능을 낼 수 있는 활성화 함수에 대해 알아보자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "r1xmaHXpLgeL",
        "outputId": "2663fb9b-4b38-4568-f75c-cd2257b9aadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n훈련 세트에 대한 성능을 보면 추가된 층이 성능을 향상시켰다는 것을 잘 알 수 있다.\\n인공 신경망에 몇 개의 층을 추가하더라도 compile() 메서드와 fit() 메서드의 사용법은 동일하다.\\n이것이 케라스 API의 장점이다.\\n\\n다음은 이미지 분류 문제에서 높은 성능을 낼 수 있는 활성화 함수에 대해 알아보자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "초창기 인공 신경망의 은닉층에 많이 사용하는 활성화 함수는 시그모이드 함수였다.\n",
        "하지만 이 함수에는 단점이 있다.\n",
        "이 함수의 오른쪽과 왼쪽 끝으로 갈수록 그래프가 누워있기 때문에\n",
        "올바른 출력을 만드는데 신속하게 대응하지 못한다.\n",
        "\n",
        "특히 층이 많은 심층 신경망일수록 그 효과가 누적되어 학습을 더 어렵게 만든다.\n",
        "이를 개선하기 위해 다른 종류의 활성화 함수가 제안되었다.\n",
        "바로 \"렐루(ReLU)\" 함수이다.\n",
        "렐루 함수는 아주 간단하다.\n",
        "입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과시키고\n",
        "음수일 경우에는 0으로 만든다.\n",
        "밑의 그림을 참고하자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "oy6Bx9OhSq5M",
        "outputId": "40ae7147-830d-49e5-aaa5-6544f03fda36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n초창기 인공 신경망의 은닉층에 많이 사용하는 활성화 함수는 시그모이드 함수였다.\\n하지만 이 함수에는 단점이 있다. \\n이 함수의 오른쪽과 왼쪽 끝으로 갈수록 그래프가 누워있기 때문에\\n올바른 출력을 만드는데 신속하게 대응하지 못한다.\\n\\n특히 층이 많은 심층 신경망일수록 그 효과가 누적되어 학습을 더 어렵게 만든다.\\n이를 개선하기 위해 다른 종류의 활성화 함수가 제안되었다.\\n바로 \"렐루(ReLU)\" 함수이다.\\n렐루 함수는 아주 간단하다.\\n입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과시키고\\n음수일 경우에는 0으로 만든다.\\n밑의 그림을 참고하자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the ReLU function\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "# Generate x values\n",
        "x = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Calculate corresponding y values using the ReLU function\n",
        "y = relu(x)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(x, y)\n",
        "plt.title(\"ReLU Function\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"ReLU(x)\")\n",
        "plt.grid(True)  # Add a grid for better visualization\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "VorhQ0c2TzIH",
        "outputId": "22254a5b-e352-467a-dd1c-786c68e12882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "렐루 함수는 max(0, z)와 같이 쓸 수 있다.\n",
        "이 함수는 z가 0보다 크면 z를 출력하고 z가 0보다 작으면 0을 출력한다.\n",
        "렐루 함수는 특히 이미지 처리에서 좋은 성능을 낸다고 알려져 있다.\n",
        "은닉층의 활성화 함수에 시그모이드 함수 대신 렐루 함수를 적용하기 전에 케라스에서 제공하는 편리한 층 하나를 더 살펴보자.\n",
        "\n",
        "패션 MNIST 데이터는 28 x 28 크기이기 때문에 인공 신경망에 주입하기 위해\n",
        "넘파이 배열이 reshape() 메서드를 사용해 1차원으로 펼쳤다.\n",
        "직접 이렇게 1차원으로 펼쳐도 좋지만 케라스에서는 이를 위한 Flatten 층을 제공한다.\n",
        "\n",
        "사실 Flatten 클래스는 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할만 한다.\n",
        "입력에 곱해지는 가중치나 절편이 없다.\n",
        "따라서 인공 신경망의 성능을 위해 기여하는 바는 없다.\n",
        "하지만 Flatten 클래스를 층처럼 입력층과 은닉층 사이에 추가하기 때문에 이를 층이라 부른다\n",
        "Flatten 층은 다음 코드처럼 입력층 바로 뒤에 추가한다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "hBvnUM3pT46m",
        "outputId": "f31e9298-bd54-475b-e172-1fee66dc4d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n렐루 함수는 max(0, z)와 같이 쓸 수 있다.\\n이 함수는 z가 0보다 크면 z를 출력하고 z가 0보다 작으면 0을 출력한다.\\n렐루 함수는 특히 이미지 처리에서 좋은 성능을 낸다고 알려져 있다.\\n은닉층의 활성화 함수에 시그모이드 함수 대신 렐루 함수를 적용하기 전에 케라스에서 제공하는 편리한 층 하나를 더 살펴보자.\\n\\n패션 MNIST 데이터는 28 x 28 크기이기 때문에 인공 신경망에 주입하기 위해\\n넘파이 배열이 reshape() 메서드를 사용해 1차원으로 펼쳤다.\\n직접 이렇게 1차원으로 펼쳐도 좋지만 케라스에서는 이를 위한 Flatten 층을 제공한다.\\n\\n사실 Flatten 클래스는 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할만 한다.\\n입력에 곱해지는 가중치나 절편이 없다.\\n따라서 인공 신경망의 성능을 위해 기여하는 바는 없다.\\n하지만 Flatten 클래스를 층처럼 입력층과 은닉층 사이에 추가하기 때문에 이를 층이라 부른다\\nFlatten 층은 다음 코드처럼 입력층 바로 뒤에 추가한다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten 층 추가\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# 왜 이미 데이터셋을 reshape() 함수를 사용해 1차원 배열로 펼쳤는데 또 펼치는 걸까?\n",
        "# 몇 가지 이점이 있기 때문임\n",
        "# 1. 데이터 전처리 과정을 모델에 포함시킬 수 있음\n",
        "# 2. 모델의 구조를 더욱 명확하게 표현할 수 있음\n",
        "# 3. 다른 종류의 입력 데이터를 처리할 수 있음\n",
        "# 따라서 Flatten 층으로 데이터를 펼치는 것이 일반적으로 권장됨 (생략해도 성능에 큰 차이가 없음)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otuPMiBuzINI",
        "outputId": "caacbb16-55e1-453e-db2c-cc97eb51a487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "첫 번째 Dense 층에 있던 input_shape 매개변수를 Flatten 층으로 옮겼다.\n",
        "또 첫 번째 Dense 층의 활성화 함수를 'relu'로 바꾼 것을 눈여겨보자.\n",
        "하지만 이 신경망을 깊이가 3인 신경망이라고는 부르지 않는다.\n",
        "Flatten 클래스는 학습하는 층이 아니기 때문이다!\n",
        "모델의 summary() 메서드를 호출해 보면 이런 점을 더욱 확실히 알 수 있을 것이다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "JrlyXf17zaOE",
        "outputId": "7b5f0215-d517-4d7c-98cc-76e02213344d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n첫 번째 Dense 층에 있던 input_shape 매개변수를 Flatten 층으로 옮겼다.\\n또 첫 번째 Dense 층의 활성화 함수를 'relu'로 바꾼 것을 눈여겨보자.\\n하지만 이 신경망을 깊이가 3인 신경망이라고는 부르지 않는다.\\nFlatten 클래스는 학습하는 층이 아니기 때문이다!\\n모델의 summary() 메서드를 호출해 보면 이런 점을 더욱 확실히 알 수 있을 것이다.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "bZiNDTofz7Vm",
        "outputId": "13fc08d5-c164-471c-88d1-eb5e4e33a76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "첫 번째 등장하는 Flatten 클래스에 포함된 모델 파라미터는 0개이다.\n",
        "케라스의 Flatten 층을 신경망 모델에 추가하면 입력값의 차원을 짐작할 수 있는 것이 또 하나의 장점이다.\n",
        "앞의 출력에서 784개의 입력이 첫 번째 은닉층에 전달된다는 것을 알 수 있는데,\n",
        "이는 이전에 만들었던 모델에서는 쉽게 눈치채기 어려웠다.\n",
        "입력 데이터에 대한 전처리 과정을 가능한 모델에 포함시키는 것이 케라스 API의 철학 중 하나이다.\n",
        "\n",
        "그럼 훈련 데이터를 다시 준비해서 모델을 훈련해 보겠다.\n",
        "이번 장의 서두에 있던 코드와 동일하지만 reshape() 메서드를 사용하지 않았다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "rWPAIPY2z8ec",
        "outputId": "febec572-5689-4389-ca64-f3760df653f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n첫 번째 등장하는 Flatten 클래스에 포함된 모델 파라미터는 0개이다.\\n케라스의 Flatten 층을 신경망 모델에 추가하면 입력값의 차원을 짐작할 수 있는 것이 또 하나의 장점이다.\\n앞의 출력에서 784개의 입력이 첫 번째 은닉층에 전달된다는 것을 알 수 있는데,\\n이는 이전에 만들었던 모델에서는 쉽게 눈치채기 어려웠다.\\n입력 데이터에 대한 전처리 과정을 가능한 모델에 포함시키는 것이 케라스 API의 철학 중 하나이다.\\n\\n그럼 훈련 데이터를 다시 준비해서 모델을 훈련해 보겠다.\\n이번 장의 서두에 있던 코드와 동일하지만 reshape() 메서드를 사용하지 않았다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 준비\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "62ZKXgzu0kKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTVVZ2MQ0tmH",
        "outputId": "f16020b6-492f-44c1-bd61-7da74de9e87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.6723\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4054\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3595\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3344\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.3177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c34f175c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 세트 성능 확인\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9nq1Vfu1Awe",
        "outputId": "6ea41c56-5277-41b2-b1e4-360fc5237b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3847014605998993, 0.8665000200271606]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "07-1장의 은닉층을 추가하지 않은 경우보다 몇 퍼센트 성능이 향상되었다.\n",
        "지금까지는 모델을 5번의 에포크 동안 훈련했다.\n",
        "이보다 더 훈련하지 않을 이유가 없다.\n",
        "그전에 인공 신경망의 하이퍼파라미터에 대해 잠시 알아보고 이번 장을 마무리할 예정이다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "SgcP7be11NzZ",
        "outputId": "470a7677-3a91-4e3b-e977-bf060b53b459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n07-1장의 은닉층을 추가하지 않은 경우보다 몇 퍼센트 성능이 향상되었다.\\n지금까지는 모델을 5번의 에포크 동안 훈련했다.\\n이보다 더 훈련하지 않을 이유가 없다.\\n그전에 인공 신경망의 하이퍼파라미터에 대해 잠시 알아보고 이번 장을 마무리할 예정이다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 옵티마이저"
      ],
      "metadata": {
        "id": "u-O3SOoO1dlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "3장에서 하이퍼파라미터는 모델이 학습하지 않아 사람이 지정해 주어야 하는 파라미터라고 설명했다.\n",
        "신경망에는 특히 하이퍼파라미터가 많다.\n",
        "어떤 하이퍼파라미터가 있는지 먼저 이번 장에서 등장한 것들을 생각해 보자.\n",
        "\n",
        "이번 장에서는 은닉층을 하나 추가했다.\n",
        "하지만 여러 개의 은닉층을 추가할 수도 있다.\n",
        "추가할 은닉층의 개수는 모델이 학습하는 것이 아니라 우리가 지정해 주어야 할 하이퍼파라미터이다.\n",
        "그럼 은닉층의 뉴런 개수도 하이퍼파라미터일까?\n",
        "그렇다. 또 활성화 함수도 선택해야 할 하이퍼파라미터 중 하나이다.\n",
        "심지어 층의 종류도 하이퍼파라미터이다.\n",
        "이 장에서는 가장 기본적인 밀집층만 다루지만, 다른 종류의 층을 선택할 수도 있다.\n",
        "\n",
        "케라스는 기본적으로 미니배치 경사 하강법을 사용하여 미니배치 개수는 32개이다.\n",
        "fit() 메서드의 batch_size 매개변수에서 이를 조정할 수 있으며 역시 하이퍼파라미터이다.\n",
        "또한 fit() 메서드의 epochs 매개변수도 하이퍼파라미터이다.\n",
        "반복 횟수에 따라 다른 모델이 만들어지기 때문이다.\n",
        "\n",
        "마지막으로 compile() 메서드에서는 케라스의 기본 경사 하강법 알고리즘인 RMSprop을 사용했다.\n",
        "케라스는 다양한 종류의 경사 하강법 알고리즘을 제공한다. 이들을 \"옵티마이저(optimizer)\"라고 부른다.\n",
        "다른 옵티마이저도 테스트해 보자.\n",
        "또한 RMSprop의 학습률 또한 조정할 하이퍼파라미터 중 하나이다.\n",
        "\n",
        "처음부터 모델을 구성하고 각종 하이퍼파라미터의 최적값을 찾는 것은 어려운 작업이다.\n",
        "여기서는 여러 가지 옵티마이저를 테스트해 보겠다.\n",
        "가장 기본적인 옵티마이저는 확률적 경사 하강법인 SGD이다.\n",
        "이름이 SGD이지만 1개의 샘플을 뽑아서 훈련하지 않고 앞서 언급한 것처럼 기본적으로 미니배치를 사용한다.\n",
        "\n",
        "옵티마이저를 간단히 말하자면..\n",
        "손실 함수는 목적지까지의 거리이고,\n",
        "옵티마이저는 목적지까지 안내하는 네비게이션이다(도구)!\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "mQcMRZeb1cwj",
        "outputId": "9bc322c2-7936-40bf-e452-0f23eb178d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n3장에서 하이퍼파라미터는 모델이 학습하지 않아 사람이 지정해 주어야 하는 파라미터라고 설명했다.\\n신경망에는 특히 하이퍼파라미터가 많다.\\n어떤 하이퍼파라미터가 있는지 먼저 이번 장에서 등장한 것들을 생각해 보자.\\n\\n이번 장에서는 은닉층을 하나 추가했다.\\n하지만 여러 개의 은닉층을 추가할 수도 있다.\\n추가할 은닉층의 개수는 모델이 학습하는 것이 아니라 우리가 지정해 주어야 할 하이퍼파라미터이다.\\n그럼 은닉층의 뉴런 개수도 하이퍼파라미터일까? \\n그렇다. 또 활성화 함수도 선택해야 할 하이퍼파라미터 중 하나이다.\\n심지어 층의 종류도 하이퍼파라미터이다.\\n이 장에서는 가장 기본적인 밀집층만 다루지만, 다른 종류의 층을 선택할 수도 있다.\\n\\n케라스는 기본적으로 미니배치 경사 하강법을 사용하여 미니배치 개수는 32개이다.\\nfit() 메서드의 batch_size 매개변수에서 이를 조정할 수 있으며 역시 하이퍼파라미터이다.\\n또한 fit() 메서드의 epochs 매개변수도 하이퍼파라미터이다.\\n반복 횟수에 따라 다른 모델이 만들어지기 때문이다.\\n\\n마지막으로 compile() 메서드에서는 케라스의 기본 경사 하강법 알고리즘인 RMSprop을 사용했다.\\n케라스는 다양한 종류의 경사 하강법 알고리즘을 제공한다. 이들을 \"옵티마이저(optimizer)\"라고 부른다.\\n다른 옵티마이저도 테스트해 보자.\\n또한 RMSprop의 학습률 또한 조정할 하이퍼파라미터 중 하나이다.\\n\\n처음부터 모델을 구성하고 각종 하이퍼파라미터의 최적값을 찾는 것은 어려운 작업이다.\\n여기서는 여러 가지 옵티마이저를 테스트해 보겠다.\\n가장 기본적인 옵티마이저는 확률적 경사 하강법인 SGD이다.\\n이름이 SGD이지만 1개의 샘플을 뽑아서 훈련하지 않고 앞서 언급한 것처럼 기본적으로 미니배치를 사용한다.\\n\\n옵티마이저를 간단히 말하자면..\\n손실 함수는 목적지까지의 거리이고,\\n옵티마이저는 목적지까지 안내하는 네비게이션이다(도구)!\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 옵티마이저를 사용하려면 compile() 메서드의 optimizer 매개변수를 'sgd'로 지정한다.\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 이 옵티마이저는 tensorflow.keras.optimizers 패키지 아래 SGD 클래스로 구현되어 있음\n",
        "# 'sgd' 문자열은 이 클래스의 기본 설정 매개변수로 생성한 객체와 동일함\n",
        "# 다음 코드는 위의 코드와 정확히 일치함"
      ],
      "metadata": {
        "id": "3w-aulL73RR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD()\n",
        "\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T0maXgp83dPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "sgd와 'sgd'의 차이는 무엇인가?\n",
        "원래 sgd = keras.optimizers.SGD()처럼 SGD 클래스 객체를 만들어 사용해야 하는데,\n",
        "번거로움을 피하고자 'sgd'라 지정하면 자동으로 SGD 클래스 객체를 만들어 준다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "eEPjeELy4GJC",
        "outputId": "c1d26b01-f66d-442c-e2fa-4b8043976077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nsgd와 'sgd'의 차이는 무엇인가?\\n원래 sgd = keras.optimizers.SGD()처럼 SGD 클래스 객체를 만들어 사용해야 하는데,\\n번거로움을 피하고자 'sgd'라 지정하면 자동으로 SGD 클래스 객체를 만들어 준다.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 클래스의 학습률 변경 (기본값은 0.01)\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "13KIq2XZ4T4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "많이 사용하는 옵티마이저들을 알아보자.\n",
        "\n",
        "기본 경사 하강법 옵티마이저 = [SGD, 모멘텀, 네스테로프 모멘텀]\n",
        "적응적 학습률 옵티마이저 = [RMSprop, Adam, Adagrad]\n",
        "\n",
        "기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공한다.\n",
        "SGD 클래스의 momentum 매개변수의 기본값은 0이다.\n",
        "이를 0보다 큰 값으로 지정하면 마치 이전의 그레이디언트 가속도처럼 사용하는 \"모멘텀 최적화(momentum optimization)\"을 사용한다.\n",
        "보통 momentum 매개변수는 0.9 이상을 지정한다.\n",
        "이전 가중치 업데이트의 \"관성\"을 이용하여 \"local minima\"를 벗어날 수 있도록 도움\n",
        "\n",
        "다음처럼 SGD 클래스의 nesterov 매개변수를 기본값 False에서 True로 바꾸면\n",
        "\"네스테로프 모멘텀 최적화(nesterov momentum optimiation)\"(또는 네스테로프 가속 경사)를 사용한다.\n",
        "모멘텀을 사용할 때, 가중치 업데이트를 미리 적용한 후 기울기를 계산하여 업데이트 방향을 보다 정확하게 예측해줌\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "Pm050zwb4ctj",
        "outputId": "eed6a160-ade0-46cb-ed26-123be08b96cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n많이 사용하는 옵티마이저들을 알아보자.\\n\\n기본 경사 하강법 옵티마이저 = [SGD, 모멘텀, 네스테로프 모멘텀]\\n적응적 학습률 옵티마이저 = [RMSprop, Adam, Adagrad]\\n\\n기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공한다.\\nSGD 클래스의 momentum 매개변수의 기본값은 0이다.\\n이를 0보다 큰 값으로 지정하면 마치 이전의 그레이디언트 가속도처럼 사용하는 \"모멘텀 최적화(momentum optimization)\"을 사용한다.\\n보통 momentum 매개변수는 0.9 이상을 지정한다.\\n\\n다음처럼 SGD 클래스의 nesterov 매개변수를 기본값 False에서 True로 바꾸면 \\n\"네스테로프 모멘텀 최적화(nesterov momentum optimiation)\"(또는 네스테로프 가속 경사)를 사용한다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "DdGXvXkn5ymf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "네스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현한다.\n",
        "대부분의 경우 네스테로프 모멘텀 최적화가 기분 확률적 경사 하강법보다 더 나은 성능을 제공한다.\n",
        "\n",
        "모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다.\n",
        "이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높다.\n",
        "이런 학습률을 \"적응적 학습률(adaptive learning rate)\"이라고 한다.\n",
        "이런 방식들은 학습률 매개변수를 튜닝하는 수고를 덜 수 있는 것이 장점이다.\n",
        "\n",
        "적응적 학습률을 사용하는 대표적인 옵티마이저는 Adagrad와 RMSprop이다.\n",
        "각각 compile() 메서드의 optimizer 매개변수에 \"adgrad\"와 \"rmsprop\"으로 지정할 수 있다.\n",
        "optimizer 매개변수의 기본값이 바로 'rmsprop'이다.\n",
        "이 두 옵티마이저의 매개변수를 바꾸고 싶다면 SGD와 같이 Adagrad와 RMSprop 클래스 객체를 만들어 사용하면 된다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "YKtS_rUP52GK",
        "outputId": "6a88a0e0-21b7-46b4-c711-100072867506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n네스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현한다.\\n대부분의 경우 네스테로프 모멘텀 최적화가 기분 확률적 경사 하강법보다 더 나은 성능을 제공한다.\\n\\n모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다.\\n이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높다.\\n이런 학습률을 \"적응적 학습률(adaptive learning rate)\"이라고 한다.\\n이런 방식들은 학습률 매개변수를 튜닝하는 수고를 덜 수 있는 것이 장점이다.\\n\\n적응적 학습률을 사용하는 대표적인 옵티마이저는 Adagrad와 RMSprop이다.\\n각각 compile() 메서드의 optimizer 매개변수에 \"adgrad\"와 \"rmsprop\"으로 지정할 수 있다.\\noptimizer 매개변수의 기본값이 바로 \\'rmsprop\\'이다.\\n이 두 옵티마이저의 매개변수를 바꾸고 싶다면 SGD와 같이 Adagrad와 RMSprop 클래스 객체를 만들어 사용하면 된다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adagrad = keras.optimizers.Adagrad()\n",
        "\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2o5V9AZ96kIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop()\n",
        "\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4Wo8kVU96tBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam이다. (모르겠으면 Adam 쓰라는 말이 있을 정도)\n",
        "Adam은 RMSprop과 함께 맨처음 시도해 볼 수 있는 좋은 알고리즘이다.\n",
        "Adam 클래스도 keras.optimizers 패키지 아래에 있다.\n",
        "적응적 학습률을 사용하는 이 3개의 클래스는 learning_rate 매개변수의 기본값으로 모두 0.001을 사용한다.\n",
        "\n",
        "여기에서는 Adam 클래스의 매개변수 기본값을 사용해 패션 MNIST 모델을 훈련해 보겠다.\n",
        "먼저 모델을 다시 생성하자.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "D6fbweQv64Nd",
        "outputId": "7dd044d0-de7c-4177-9055-cb2c234cdecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam이다. (모르겠으면 Adam 쓰라는 말이 있을 정도)\\nAdam은 RMSprop과 함께 맨처음 시도해 볼 수 있는 좋은 알고리즘이다.\\nAdam 클래스도 keras.optimizers 패키지 아래에 있다.\\n적응적 학습률을 사용하는 이 3개의 클래스는 learning_rate 매개변수의 기본값으로 모두 0.001을 사용한다.\\n\\n여기에서는 Adam 클래스의 매개변수 기본값을 사용해 패션 MNIST 모델을 훈련해 보겠다.\\n먼저 모델을 다시 생성하자.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 재생성\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "XuKQqYxq7TMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile() 메서드의 optimizer로 adam 사용\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD_JKvYm7f0u",
        "outputId": "493a9f18-42ec-4a5d-deef-cafa7a8247a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7691 - loss: 0.6706\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4134\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3618\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.3302\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.3088\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c34e853d1e0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 세트 성능 확인\n",
        "model.evaluate(val_scaled, val_target)\n",
        "\n",
        "# 기본 RMSprop보다 조금 더 나은 성능을 내는 것을 확인할 수 있음!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vvpJSOw7tOG",
        "outputId": "5a12e312-b070-493c-dd1a-430ad7f1efb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.3506\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35239022970199585, 0.8725833296775818]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}
